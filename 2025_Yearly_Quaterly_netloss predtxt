
#2025 pred
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from scipy import stats

# Function to generate random dates
def random_dates(start, end, n=10):
    return [start + timedelta(days=np.random.randint(0, (end - start).days)) for _ in range(n)]

# Parameters
num_records = 10000
start_date = datetime.now() - timedelta(days=4*365)
end_date = datetime.now()

# Expanded categories
business_lines = [
    "Retail", "Corporate Banking", "Investment Banking", "Insurance",
    "Wealth Management", "Asset Management", "Private Banking",
    "Credit Card Services", "Mortgage Lending", "Financial Advisory"
]

event_types = [
    "Fraud", "System Failure", "Theft", "Compliance", "Natural Disaster",
    "Cyber Attack", "Market Risk", "Operational Error", "Vendor Risk", "Regulatory Violation"
]

# Generate data
data = {
    "Date": random_dates(start_date, end_date, num_records),
    "Unique Event ID": [f"EID{str(i).zfill(5)}" for i in range(num_records)],
    "Event Type": np.random.choice(event_types, num_records),
    "Business Line": np.random.choice(business_lines, num_records),
    "Event Description": np.random.choice(
        [
            "Unauthorized transaction", "Server downtime", "Lost assets", 
            "Regulatory fines", "Data breach", "Network failure", 
            "Inadequate compliance", "Financial misstatement", 
            "Supplier issues", "Internal fraud"
        ],
        num_records
    ),
    "Net Loss Amount": np.random.choice(
        [np.random.uniform(-10000, 0) for _ in range(num_records // 2)] + 
        [np.random.uniform(0, 10000) for _ in range(num_records // 2)],
        num_records
    )
}

# Create DataFrame
df = pd.DataFrame(data)

# Add a Year column
df['Year'] = df['Date'].dt.year
from scipy.stats import poisson, lognorm
import pandas as pd
import numpy as np

# Function to calculate VaR for Net Loss using Monte Carlo
def calculate_net_loss_var(frequency_lambda, severity_shape, severity_scale, severity_loc, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts (frequency) using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Simulate severity amounts (loss) using Log-Normal distribution
    simulated_loss_amounts = lognorm.rvs(s=severity_shape, loc=severity_loc, scale=severity_scale, size=n_simulations)
    # Total losses = frequency * severity
    total_losses = simulated_event_counts * simulated_loss_amounts
    # Calculate VaR
    var_value = np.percentile(total_losses, confidence_level * 100)
    return var_value

# Function to calculate VaR for Event Counts using Monte Carlo
def calculate_event_count_var(frequency_lambda, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Calculate VaR
    var_event_count = np.percentile(simulated_event_counts, confidence_level * 100)
    return var_event_count

# Prepare results
results = []

# Define confidence level and number of simulations
confidence_level = 0.999
n_simulations = 10000

# Loop through each year and business line
for year in range(2021, 2025):
    yearly_data = df[df['Year'] == year]
    
    for business_line in yearly_data['Business Line'].unique():
        # Filter data for the specific year and business line
        bl_data = yearly_data[yearly_data['Business Line'] == business_line]
        
        # Total event counts and net loss
        total_event_count = bl_data.shape[0]
        total_net_loss = bl_data['Net Loss Amount'].sum()
        
        # Frequency parameter (Poisson Î»)
        frequency_lambda = total_event_count / 1  # Events per year
        
        # Severity parameters (Log-Normal distribution)
        positive_losses = bl_data[bl_data['Net Loss Amount'] > 0]['Net Loss Amount']
        if positive_losses.empty:
            print(f"No positive losses for {business_line} in {year}. Skipping.")
            continue
        severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
        
        # Calculate VaR for Net Loss
        var_net_loss = calculate_net_loss_var(
            frequency_lambda=frequency_lambda,
            severity_shape=severity_shape,
            severity_scale=severity_scale,
            severity_loc=severity_loc,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Calculate VaR for Event Count
        var_event_count = calculate_event_count_var(
            frequency_lambda=frequency_lambda,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Append results
        results.append({
            'Year': year,
            'Business Line': business_line,
            'Total Net Loss': total_net_loss,
            'Total Event Count': total_event_count,
            'VaR Net Loss (99.9%)': var_net_loss,
            'VaR Event Count (99.9%)': var_event_count
        })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Display results
print(results_df)
    Year         Business Line  Total Net Loss  Total Event Count  \
0   2021    Financial Advisory   -78145.771170                245   
1   2021     Corporate Banking    99542.018586                266   
2   2021     Wealth Management   -60877.454977                252   
3   2021             Insurance   156697.282395                249   
4   2021  Credit Card Services     5889.617493                243   
5   2021       Private Banking   -77578.507055                242   
6   2021                Retail   -20954.033397                257   
7   2021      Mortgage Lending    -3899.980475                240   
8   2021      Asset Management   176338.817808                247   
9   2021    Investment Banking   179794.408014                238   
10  2022     Corporate Banking    18193.929469                260   
11  2022       Private Banking   -33976.328811                254   
12  2022  Credit Card Services   -82309.718540                251   
13  2022             Insurance   -16142.629347                255   
14  2022    Financial Advisory    87341.758569                246   
15  2022                Retail    13407.872118                253   
16  2022    Investment Banking  -101280.796926                241   
17  2022     Wealth Management    11733.876674                281   
18  2022      Asset Management   157000.986098                234   
19  2022      Mortgage Lending   -74803.655770                238   
20  2023    Investment Banking    33338.138062                237   
21  2023    Financial Advisory    15004.547601                262   
22  2023                Retail    50628.122175                267   
23  2023  Credit Card Services    26313.495720                253   
24  2023     Corporate Banking   -12827.679576                251   
25  2023             Insurance  -110257.898936                238   
26  2023       Private Banking   -22163.084418                271   
27  2023      Asset Management   -31819.425366                246   
28  2023      Mortgage Lending    30396.605846                263   
29  2023     Wealth Management  -110560.795976                233   
30  2024      Asset Management   -46327.209590                247   
31  2024                Retail  -102593.612666                234   
32  2024             Insurance   -14541.568364                235   
33  2024      Mortgage Lending    18187.964134                203   
34  2024       Private Banking   -62465.740114                217   
35  2024    Investment Banking    -6504.763801                230   
36  2024  Credit Card Services    50165.402863                222   
37  2024    Financial Advisory    52660.980970                234   
38  2024     Wealth Management   175851.809489                236   
39  2024     Corporate Banking   -10575.359749                259   

    VaR Net Loss (99.9%)  VaR Event Count (99.9%)  
0           3.533364e+06                  294.000  
1           3.919443e+06                  317.001  
2           3.563508e+06                  304.000  
3           3.747867e+06                  299.001  
4           3.638037e+06                  294.001  
5           3.588097e+06                  290.000  
6           3.752120e+06                  308.000  
7           3.691276e+06                  290.000  
8           3.406660e+06                  297.000  
9           3.542307e+06                  286.000  
10          3.744729e+06                  311.000  
11          3.671334e+06                  306.000  
12          4.507686e+06                  303.002  
13          3.750001e+06                  305.000  
14          3.371747e+06                  292.001  
15          3.533035e+06                  301.001  
16          3.547497e+06                  292.000  
17          3.983150e+06                  333.002  
18          3.252231e+06                  283.000  
19          3.550755e+06                  289.001  
20          3.538986e+06                  287.000  
21          3.946689e+06                  315.000  
22          3.904230e+06                  317.001  
23          3.513694e+06                  305.000  
24          3.527429e+06                  300.002  
25          3.712868e+06                  285.001  
26          3.591322e+06                  324.000  
27          3.698809e+06                  297.001  
28          3.709206e+06                  316.004  
29          3.247310e+06                  284.001  
30          3.701669e+06                  296.001  
31          3.563720e+06                  282.001  
32          3.313891e+06                  284.001  
33          2.839916e+06                  247.001  
34          3.452581e+06                  264.001  
35          3.241453e+06                  277.000  
36          3.236423e+06                  268.001  
37          3.421268e+06                  281.000  
38          3.638142e+06                  283.000  
39          3.696070e+06                  308.000  
results_df
Year	Business Line	Total Net Loss	Total Event Count	VaR Net Loss (99.9%)	VaR Event Count (99.9%)
0	2021	Financial Advisory	-78145.771170	245	3.533364e+06	294.000
1	2021	Corporate Banking	99542.018586	266	3.919443e+06	317.001
2	2021	Wealth Management	-60877.454977	252	3.563508e+06	304.000
3	2021	Insurance	156697.282395	249	3.747867e+06	299.001
4	2021	Credit Card Services	5889.617493	243	3.638037e+06	294.001
5	2021	Private Banking	-77578.507055	242	3.588097e+06	290.000
6	2021	Retail	-20954.033397	257	3.752120e+06	308.000
7	2021	Mortgage Lending	-3899.980475	240	3.691276e+06	290.000
8	2021	Asset Management	176338.817808	247	3.406660e+06	297.000
9	2021	Investment Banking	179794.408014	238	3.542307e+06	286.000
10	2022	Corporate Banking	18193.929469	260	3.744729e+06	311.000
11	2022	Private Banking	-33976.328811	254	3.671334e+06	306.000
12	2022	Credit Card Services	-82309.718540	251	4.507686e+06	303.002
13	2022	Insurance	-16142.629347	255	3.750001e+06	305.000
14	2022	Financial Advisory	87341.758569	246	3.371747e+06	292.001
15	2022	Retail	13407.872118	253	3.533035e+06	301.001
16	2022	Investment Banking	-101280.796926	241	3.547497e+06	292.000
17	2022	Wealth Management	11733.876674	281	3.983150e+06	333.002
18	2022	Asset Management	157000.986098	234	3.252231e+06	283.000
19	2022	Mortgage Lending	-74803.655770	238	3.550755e+06	289.001
20	2023	Investment Banking	33338.138062	237	3.538986e+06	287.000
21	2023	Financial Advisory	15004.547601	262	3.946689e+06	315.000
22	2023	Retail	50628.122175	267	3.904230e+06	317.001
23	2023	Credit Card Services	26313.495720	253	3.513694e+06	305.000
24	2023	Corporate Banking	-12827.679576	251	3.527429e+06	300.002
25	2023	Insurance	-110257.898936	238	3.712868e+06	285.001
26	2023	Private Banking	-22163.084418	271	3.591322e+06	324.000
27	2023	Asset Management	-31819.425366	246	3.698809e+06	297.001
28	2023	Mortgage Lending	30396.605846	263	3.709206e+06	316.004
29	2023	Wealth Management	-110560.795976	233	3.247310e+06	284.001
30	2024	Asset Management	-46327.209590	247	3.701669e+06	296.001
31	2024	Retail	-102593.612666	234	3.563720e+06	282.001
32	2024	Insurance	-14541.568364	235	3.313891e+06	284.001
33	2024	Mortgage Lending	18187.964134	203	2.839916e+06	247.001
34	2024	Private Banking	-62465.740114	217	3.452581e+06	264.001
35	2024	Investment Banking	-6504.763801	230	3.241453e+06	277.000
36	2024	Credit Card Services	50165.402863	222	3.236423e+06	268.001
37	2024	Financial Advisory	52660.980970	234	3.421268e+06	281.000
38	2024	Wealth Management	175851.809489	236	3.638142e+06	283.000
39	2024	Corporate Banking	-10575.359749	259	3.696070e+06	308.000
# Placeholder for results
results_2025 = []

# Simulate 2025 VaR calculations
year = 2025

for business_line in df['Business Line'].unique():
    # Filter data for prior years to estimate parameters
    historical_data = df[df['Business Line'] == business_line]
    
    # Total event counts and net loss (assume mean from historical data)
    total_event_count = historical_data.shape[0] // 4  # Approximate yearly count
    total_net_loss = historical_data['Net Loss Amount'].sum() / 4  # Approximate yearly loss
    
    # Frequency parameter (Poisson Î»)
    frequency_lambda = total_event_count / 1  # Events per year
    
    # Severity parameters (Log-Normal distribution)
    positive_losses = historical_data[historical_data['Net Loss Amount'] > 0]['Net Loss Amount']
    if positive_losses.empty:
        print(f"No positive losses for {business_line} in {year}. Skipping.")
        continue
    severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
    
    # Calculate VaR for Net Loss
    var_net_loss = calculate_net_loss_var(
        frequency_lambda=frequency_lambda,
        severity_shape=severity_shape,
        severity_scale=severity_scale,
        severity_loc=severity_loc,
        confidence_level=confidence_level,
        n_simulations=n_simulations
    )
    
    # Calculate VaR for Event Count
    var_event_count = calculate_event_count_var(
        frequency_lambda=frequency_lambda,
        confidence_level=confidence_level,
        n_simulations=n_simulations
    )
    
    # Append results
    results_2025.append({
        'Year': year,
        'Business Line': business_line,
        'Total Net Loss': total_net_loss,
        'Total Event Count': total_event_count,
        'VaR Net Loss (99.9%)': var_net_loss,
        'VaR Event Count (99.9%)': var_event_count
    })

# Convert results to DataFrame
results_2025_df = pd.DataFrame(results_2025)

# Display the final results
print(results_2025_df)
   Year         Business Line  Total Net Loss  Total Event Count  \
0  2025     Corporate Banking    29962.117515                262   
1  2025      Asset Management    71970.801175                248   
2  2025    Financial Advisory    18398.411865                251   
3  2025    Investment Banking    21591.238675                240   
4  2025       Private Banking   -51987.639937                250   
5  2025     Wealth Management    -7121.790578                254   
6  2025             Insurance     8013.643027                247   
7  2025                Retail   -14479.460658                257   
8  2025  Credit Card Services     4501.761419                246   
9  2025      Mortgage Lending    -8200.837693                241   

   VaR Net Loss (99.9%)  VaR Event Count (99.9%)  
0          3.716468e+06                  312.000  
1          3.730043e+06                  298.000  
2          3.430944e+06                  302.000  
3          3.514980e+06                  290.000  
4          3.472847e+06                  301.001  
5          3.646000e+06                  303.000  
6          3.454307e+06                  299.000  
7          3.725720e+06                  307.002  
8          3.743335e+06                  292.002  
9          3.589001e+06                  291.000  
results_2025_df
Year	Business Line	Total Net Loss	Total Event Count	VaR Net Loss (99.9%)	VaR Event Count (99.9%)
0	2025	Corporate Banking	29962.117515	262	3.716468e+06	312.000
1	2025	Asset Management	71970.801175	248	3.730043e+06	298.000
2	2025	Financial Advisory	18398.411865	251	3.430944e+06	302.000
3	2025	Investment Banking	21591.238675	240	3.514980e+06	290.000
4	2025	Private Banking	-51987.639937	250	3.472847e+06	301.001
5	2025	Wealth Management	-7121.790578	254	3.646000e+06	303.000
6	2025	Insurance	8013.643027	247	3.454307e+06	299.000
7	2025	Retail	-14479.460658	257	3.725720e+06	307.002
8	2025	Credit Card Services	4501.761419	246	3.743335e+06	292.002
9	2025	Mortgage Lending	-8200.837693	241	3.589001e+06	291.000
import matplotlib.pyplot as plt
import seaborn as sns

# Ensure we have results for 2025 in results_2025_df
if 'results_2025_df' in locals():
    comparison_df = results_2025_df[['Business Line', 'Total Net Loss', 'VaR Net Loss (99.9%)']]
    
    # Sort by total net loss for better visual clarity
    comparison_df = comparison_df.sort_values('Total Net Loss', ascending=False)
    
    # Plot the comparison
    plt.figure(figsize=(12, 6))
    bar_width = 0.35
    index = range(len(comparison_df))
    
    # Bar chart for Total Net Loss
    plt.bar(index, comparison_df['Total Net Loss'], bar_width, label='Total Net Loss', color='skyblue')
    
    # Bar chart for VaR Net Loss
    plt.bar(
        [i + bar_width for i in index],
        comparison_df['VaR Net Loss (99.9%)'],
        bar_width,
        label='VaR Net Loss (99.9%)',
        color='orange'
    )
    
    # Adding labels and title
    plt.xlabel('Business Line', fontsize=12)
    plt.ylabel('Amount', fontsize=12)
    plt.title('Comparison of Total Net Loss vs VaR Net Loss (99.9%) in 2025', fontsize=14)
    plt.xticks([i + bar_width / 2 for i in index], comparison_df['Business Line'], rotation=45, ha='right')
    plt.legend()
    
    # Show the plot
    plt.tight_layout()
    plt.show()
else:
    print("The results for 2025 are not available. Please calculate them first.")

import matplotlib.pyplot as plt

# Ensure we have results for 2025 in results_2025_df
if 'results_2025_df' in locals():
    # Prepare data for plotting
    comparison_df = results_2025_df[['Business Line', 'Total Net Loss', 'VaR Net Loss (99.9%)']]
    comparison_df = comparison_df.sort_values('Total Net Loss', ascending=False)  # Sort by Total Net Loss

    # Plot the line chart
    plt.figure(figsize=(12, 6))
    
    # Plot Total Net Loss
    plt.plot(
        comparison_df['Business Line'], 
        comparison_df['Total Net Loss'], 
        marker='o', 
        label='Total Net Loss', 
        color='skyblue', 
        linewidth=2
    )
    
    # Plot VaR Net Loss
    plt.plot(
        comparison_df['Business Line'], 
        comparison_df['VaR Net Loss (99.9%)'], 
        marker='o', 
        label='VaR Net Loss (99.9%)', 
        color='orange', 
        linewidth=2
    )
    
    # Add labels, title, and legend
    plt.xlabel('Business Line', fontsize=12)
    plt.ylabel('Amount', fontsize=12)
    plt.title('Comparison of Total Net Loss vs VaR Net Loss (99.9%) in 2025', fontsize=14)
    plt.xticks(rotation=45, ha='right')
    plt.legend()
    
    # Show the plot
    plt.tight_layout()
    plt.show()
else:
    print("The results for 2025 are not available. Please calculate them first.")

import matplotlib.pyplot as plt

# Ensure we have results for 2025 in results_2025_df
if 'results_2025_df' in locals():
    # Prepare data for plotting
    comparison_event_df = results_2025_df[['Business Line', 'Total Event Count', 'VaR Event Count (99.9%)']]
    comparison_event_df = comparison_event_df.sort_values('Total Event Count', ascending=False)  # Sort by Total Event Count

    # Plot the line chart
    plt.figure(figsize=(12, 6))
    
    # Plot Total Event Count
    plt.plot(
        comparison_event_df['Business Line'], 
        comparison_event_df['Total Event Count'], 
        marker='o', 
        label='Total Event Count', 
        color='green', 
        linewidth=2
    )
    
    # Plot VaR Event Count
    plt.plot(
        comparison_event_df['Business Line'], 
        comparison_event_df['VaR Event Count (99.9%)'], 
        marker='o', 
        label='VaR Event Count (99.9%)', 
        color='red', 
        linewidth=2
    )
    
    # Add labels, title, and legend
    plt.xlabel('Business Line', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.title('Comparison of Total Event Count vs VaR Event Count (99.9%) in 2025', fontsize=14)
    plt.xticks(rotation=45, ha='right')
    plt.legend()
    
    # Show the plot
    plt.tight_layout()
    plt.show()
else:
    print("The results for 2025 are not available. Please calculate them first.")

#quarter wise result
import pandas as pd
import numpy as np
from datetime import datetime
from scipy.stats import poisson, lognorm

# Function to calculate VaR for Net Loss using Monte Carlo
def calculate_net_loss_var(frequency_lambda, severity_shape, severity_scale, severity_loc, confidence_level=0.999, n_simulations=10000):
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    simulated_loss_amounts = lognorm.rvs(s=severity_shape, loc=severity_loc, scale=severity_scale, size=n_simulations)
    total_losses = simulated_event_counts * simulated_loss_amounts
    var_value = np.percentile(total_losses, confidence_level * 100)
    return var_value

# Function to calculate VaR for Event Counts using Monte Carlo
def calculate_event_count_var(frequency_lambda, confidence_level=0.999, n_simulations=10000):
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    var_event_count = np.percentile(simulated_event_counts, confidence_level * 100)
    return var_event_count

# Prepare results list
results = []

# Define confidence level and number of simulations
confidence_level = 0.999
n_simulations = 10000

# Loop through each year and quarter, and business line
for year in range(2021, 2025):
    yearly_data = df[df['Year'] == year]
    
    for quarter in range(1, 5):  # 1 to 4 for quarters
        quarterly_data = yearly_data[yearly_data['Date'].dt.quarter == quarter]
        
        for business_line in quarterly_data['Business Line'].unique():
            bl_data = quarterly_data[quarterly_data['Business Line'] == business_line]
            
            # Total event counts and net loss
            total_event_count = bl_data.shape[0]
            total_net_loss = bl_data['Net Loss Amount'].sum()
            
            # Frequency parameter (Poisson Î»)
            frequency_lambda = total_event_count / 1  # Events per quarter
            
            # Severity parameters (Log-Normal distribution)
            positive_losses = bl_data[bl_data['Net Loss Amount'] > 0]['Net Loss Amount']
            if positive_losses.empty:
                print(f"No positive losses for {business_line} in {year} Q{quarter}. Skipping.")
                continue
            severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
            
            # Calculate VaR for Net Loss
            var_net_loss = calculate_net_loss_var(
                frequency_lambda=frequency_lambda,
                severity_shape=severity_shape,
                severity_scale=severity_scale,
                severity_loc=severity_loc,
                confidence_level=confidence_level,
                n_simulations=n_simulations
            )
            
            # Calculate VaR for Event Count
            var_event_count = calculate_event_count_var(
                frequency_lambda=frequency_lambda,
                confidence_level=confidence_level,
                n_simulations=n_simulations
            )
            
            # Append results
            results.append({
                'Year': year,
                'Quarter': quarter,
                'Business Line': business_line,
                'Total Net Loss': total_net_loss,
                'Total Event Count': total_event_count,
                'VaR Net Loss (99.9%)': var_net_loss,
                'VaR Event Count (99.9%)': var_event_count
            })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Display results
print(results_df)
     Year  Quarter         Business Line  Total Net Loss  Total Event Count  \
0    2021        1    Financial Advisory    21429.343283                 55   
1    2021        1  Credit Card Services   -44849.952062                 80   
2    2021        1             Insurance    65792.165805                 68   
3    2021        1      Mortgage Lending   -63825.921097                 64   
4    2021        1    Investment Banking    73891.712727                 57   
..    ...      ...                   ...             ...                ...   
155  2024        4     Wealth Management   -13210.661587                 43   
156  2024        4    Financial Advisory   -48279.330646                 47   
157  2024        4             Insurance   -81060.305781                 55   
158  2024        4       Private Banking     -347.608477                 50   
159  2024        4  Credit Card Services    52794.292218                 43   

     VaR Net Loss (99.9%)  VaR Event Count (99.9%)  
0            8.477202e+05                   80.001  
1            1.955785e+06                  107.000  
2            1.019612e+06                   94.001  
3            1.076776e+06                   89.001  
4            9.103160e+05                   81.001  
..                    ...                      ...  
155          6.714633e+05                   64.000  
156          8.146994e+05                   70.000  
157          9.015184e+05                   78.001  
158          8.106497e+05                   72.000  
159          6.995927e+05                   64.001  

[160 rows x 7 columns]
results_df
Year	Quarter	Business Line	Total Net Loss	Total Event Count	VaR Net Loss (99.9%)	VaR Event Count (99.9%)
0	2021	1	Financial Advisory	21429.343283	55	8.477202e+05	80.001
1	2021	1	Credit Card Services	-44849.952062	80	1.955785e+06	107.000
2	2021	1	Insurance	65792.165805	68	1.019612e+06	94.001
3	2021	1	Mortgage Lending	-63825.921097	64	1.076776e+06	89.001
4	2021	1	Investment Banking	73891.712727	57	9.103160e+05	81.001
...	...	...	...	...	...	...	...
155	2024	4	Wealth Management	-13210.661587	43	6.714633e+05	64.000
156	2024	4	Financial Advisory	-48279.330646	47	8.146994e+05	70.000
157	2024	4	Insurance	-81060.305781	55	9.015184e+05	78.001
158	2024	4	Private Banking	-347.608477	50	8.106497e+05	72.000
159	2024	4	Credit Card Services	52794.292218	43	6.995927e+05	64.001
160 rows Ã 7 columns

# Placeholder for results for 2025
results_2025 = []

# Simulate 2025 VaR calculations
year = 2025

# Loop through each business line
for business_line in df['Business Line'].unique():
    # Filter data for prior years to estimate parameters
    historical_data = df[df['Business Line'] == business_line]
    
    # Loop through each quarter (1 to 4)
    for quarter in range(1, 5):
        # Filter the data for the given quarter in historical data
        quarterly_data = historical_data[historical_data['Date'].dt.quarter == quarter]
        
        # Total event counts and net loss (assume mean from historical data)
        total_event_count = quarterly_data.shape[0]  # Total number of events in the quarter
        total_net_loss = quarterly_data['Net Loss Amount'].sum()  # Total loss in the quarter
        
        # Frequency parameter (Poisson Î»)
        frequency_lambda = total_event_count / 1  # Events per quarter
        
        # Severity parameters (Log-Normal distribution)
        positive_losses = quarterly_data[quarterly_data['Net Loss Amount'] > 0]['Net Loss Amount']
        if positive_losses.empty:
            print(f"No positive losses for {business_line} in {year} Q{quarter}. Skipping.")
            continue
        severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
        
        # Calculate VaR for Net Loss
        var_net_loss = calculate_net_loss_var(
            frequency_lambda=frequency_lambda,
            severity_shape=severity_shape,
            severity_scale=severity_scale,
            severity_loc=severity_loc,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Calculate VaR for Event Count
        var_event_count = calculate_event_count_var(
            frequency_lambda=frequency_lambda,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Append results
        results_2025.append({
            'Year': year,
            'Quarter': quarter,
            'Business Line': business_line,
            'Total Net Loss': total_net_loss,
            'Total Event Count': total_event_count,
            'VaR Net Loss (99.9%)': var_net_loss,
            'VaR Event Count (99.9%)': var_event_count
        })

# Convert results to DataFrame
results_2025_df = pd.DataFrame(results_2025)

# Display the final results
print(results_2025_df)
    Year  Quarter         Business Line  Total Net Loss  Total Event Count  \
0   2025        1     Corporate Banking    57474.623200                267   
1   2025        2     Corporate Banking   113952.847583                264   
2   2025        3     Corporate Banking   -60160.170269                239   
3   2025        4     Corporate Banking     8581.169545                280   
4   2025        1      Asset Management    -4317.967401                238   
5   2025        2      Asset Management    21723.451804                266   
6   2025        3      Asset Management   128166.834945                230   
7   2025        4      Asset Management   142310.885354                261   
8   2025        1    Financial Advisory    78682.841936                239   
9   2025        2    Financial Advisory    68503.424068                240   
10  2025        3    Financial Advisory   -27067.395507                251   
11  2025        4    Financial Advisory   -46525.223038                275   
12  2025        1    Investment Banking    10102.244982                225   
13  2025        2    Investment Banking   -37149.029766                238   
14  2025        3    Investment Banking   125636.607135                248   
15  2025        4    Investment Banking   -12224.867652                251   
16  2025        1       Private Banking   -81964.044145                235   
17  2025        2       Private Banking   -13550.461775                268   
18  2025        3       Private Banking  -104304.323685                240   
19  2025        4       Private Banking    -8131.730143                259   
20  2025        1     Wealth Management   -34788.185484                282   
21  2025        2     Wealth Management   -12216.144147                231   
22  2025        3     Wealth Management    23591.314885                286   
23  2025        4     Wealth Management    -5074.147564                220   
24  2025        1             Insurance   168562.247735                238   
25  2025        2             Insurance    11851.827345                252   
26  2025        3             Insurance  -131669.861547                235   
27  2025        4             Insurance   -16689.641424                264   
28  2025        1                Retail    -7525.007941                248   
29  2025        2                Retail  -149970.926283                245   
30  2025        3                Retail    99084.856091                263   
31  2025        4                Retail      493.235502                272   
32  2025        1  Credit Card Services   -50311.432571                257   
33  2025        2  Credit Card Services  -140231.434239                224   
34  2025        3  Credit Card Services    44285.814380                261   
35  2025        4  Credit Card Services   164264.098104                244   
36  2025        1      Mortgage Lending   -71562.538270                237   
37  2025        2      Mortgage Lending   -61942.246097                212   
38  2025        3      Mortgage Lending   103352.899244                263   
39  2025        4      Mortgage Lending    -2651.465647                252   

    VaR Net Loss (99.9%)  VaR Event Count (99.9%)  
0           3.683094e+06                  317.000  
1           3.868813e+06                  316.000  
2           3.523935e+06                  288.001  
3           3.989384e+06                  332.001  
4           3.590850e+06                  285.001  
5           3.638777e+06                  317.000  
6           3.492780e+06                  276.000  
7           3.774791e+06                  312.001  
8           3.359653e+06                  287.000  
9           3.499587e+06                  291.000  
10          3.734112e+06                  302.001  
11          3.938816e+06                  329.000  
12          3.221678e+06                  277.001  
13          3.527739e+06                  286.000  
14          3.627863e+06                  297.000  
15          5.000274e+06                  302.001  
16          3.491078e+06                  281.001  
17          3.951357e+06                  320.002  
18          3.534466e+06                  291.000  
19          3.847874e+06                  310.001  
20          4.032139e+06                  336.000  
21          3.208440e+06                  279.001  
22          4.109418e+06                  337.001  
23          3.147007e+06                  268.000  
24          3.346190e+06                  287.001  
25          3.527363e+06                  303.000  
26          3.328916e+06                  285.000  
27          3.721788e+06                  315.000  
28          3.523744e+06                  299.000  
29          3.421935e+06                  296.000  
30          3.910542e+06                  313.000  
31          4.522345e+06                  323.000  
32          4.757312e+06                  307.000  
33          3.701013e+06                  272.000  
34          3.704632e+06                  314.000  
35          3.278481e+06                  296.002  
36          3.543608e+06                  283.001  
37          4.417342e+06                  257.000  
38          3.683939e+06                  315.000  
39          3.532667e+06                  300.001  
results_2025_df
Year	Quarter	Business Line	Total Net Loss	Total Event Count	VaR Net Loss (99.9%)	VaR Event Count (99.9%)
0	2025	1	Corporate Banking	57474.623200	267	3.683094e+06	317.000
1	2025	2	Corporate Banking	113952.847583	264	3.868813e+06	316.000
2	2025	3	Corporate Banking	-60160.170269	239	3.523935e+06	288.001
3	2025	4	Corporate Banking	8581.169545	280	3.989384e+06	332.001
4	2025	1	Asset Management	-4317.967401	238	3.590850e+06	285.001
5	2025	2	Asset Management	21723.451804	266	3.638777e+06	317.000
6	2025	3	Asset Management	128166.834945	230	3.492780e+06	276.000
7	2025	4	Asset Management	142310.885354	261	3.774791e+06	312.001
8	2025	1	Financial Advisory	78682.841936	239	3.359653e+06	287.000
9	2025	2	Financial Advisory	68503.424068	240	3.499587e+06	291.000
10	2025	3	Financial Advisory	-27067.395507	251	3.734112e+06	302.001
11	2025	4	Financial Advisory	-46525.223038	275	3.938816e+06	329.000
12	2025	1	Investment Banking	10102.244982	225	3.221678e+06	277.001
13	2025	2	Investment Banking	-37149.029766	238	3.527739e+06	286.000
14	2025	3	Investment Banking	125636.607135	248	3.627863e+06	297.000
15	2025	4	Investment Banking	-12224.867652	251	5.000274e+06	302.001
16	2025	1	Private Banking	-81964.044145	235	3.491078e+06	281.001
17	2025	2	Private Banking	-13550.461775	268	3.951357e+06	320.002
18	2025	3	Private Banking	-104304.323685	240	3.534466e+06	291.000
19	2025	4	Private Banking	-8131.730143	259	3.847874e+06	310.001
20	2025	1	Wealth Management	-34788.185484	282	4.032139e+06	336.000
21	2025	2	Wealth Management	-12216.144147	231	3.208440e+06	279.001
22	2025	3	Wealth Management	23591.314885	286	4.109418e+06	337.001
23	2025	4	Wealth Management	-5074.147564	220	3.147007e+06	268.000
24	2025	1	Insurance	168562.247735	238	3.346190e+06	287.001
25	2025	2	Insurance	11851.827345	252	3.527363e+06	303.000
26	2025	3	Insurance	-131669.861547	235	3.328916e+06	285.000
27	2025	4	Insurance	-16689.641424	264	3.721788e+06	315.000
28	2025	1	Retail	-7525.007941	248	3.523744e+06	299.000
29	2025	2	Retail	-149970.926283	245	3.421935e+06	296.000
30	2025	3	Retail	99084.856091	263	3.910542e+06	313.000
31	2025	4	Retail	493.235502	272	4.522345e+06	323.000
32	2025	1	Credit Card Services	-50311.432571	257	4.757312e+06	307.000
33	2025	2	Credit Card Services	-140231.434239	224	3.701013e+06	272.000
34	2025	3	Credit Card Services	44285.814380	261	3.704632e+06	314.000
35	2025	4	Credit Card Services	164264.098104	244	3.278481e+06	296.002
36	2025	1	Mortgage Lending	-71562.538270	237	3.543608e+06	283.001
37	2025	2	Mortgage Lending	-61942.246097	212	4.417342e+06	257.000
38	2025	3	Mortgage Lending	103352.899244	263	3.683939e+06	315.000
39	2025	4	Mortgage Lending	-2651.465647	252	3.532667e+06	300.001
#different percentile 99,90,95
import pandas as pd
import numpy as np
from scipy.stats import poisson, lognorm

# Function to calculate VaR for Net Loss using Monte Carlo
def calculate_net_loss_var(frequency_lambda, severity_shape, severity_scale, severity_loc, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts (frequency) using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Simulate severity amounts (loss) using Log-Normal distribution
    simulated_loss_amounts = lognorm.rvs(s=severity_shape, loc=severity_loc, scale=severity_scale, size=n_simulations)
    # Total losses = frequency * severity
    total_losses = simulated_event_counts * simulated_loss_amounts
    # Calculate VaR
    var_value = np.percentile(total_losses, confidence_level * 100)
    return var_value

# Function to calculate VaR for Event Counts using Monte Carlo
def calculate_event_count_var(frequency_lambda, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Calculate VaR
    var_event_count = np.percentile(simulated_event_counts, confidence_level * 100)
    return var_event_count

# Prepare results
results = []

# Define the confidence levels and number of simulations
confidence_levels = [0.999, 0.95, 0.90]  # 99%, 95%, and 90%
n_simulations = 10000

# Loop through each year and business line
for year in range(2021, 2025):
    yearly_data = df[df['Year'] == year]
    
    for business_line in yearly_data['Business Line'].unique():
        # Filter data for the specific year and business line
        bl_data = yearly_data[yearly_data['Business Line'] == business_line]
        
        # Total event counts and net loss
        total_event_count = bl_data.shape[0]
        total_net_loss = bl_data['Net Loss Amount'].sum()
        
        # Frequency parameter (Poisson Î»)
        frequency_lambda = total_event_count / 1  # Events per year
        
        # Severity parameters (Log-Normal distribution)
        positive_losses = bl_data[bl_data['Net Loss Amount'] > 0]['Net Loss Amount']
        if positive_losses.empty:
            print(f"No positive losses for {business_line} in {year}. Skipping.")
            continue
        severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
        
        # Calculate VaR for each confidence level
        for confidence_level in confidence_levels:
            var_net_loss = calculate_net_loss_var(
                frequency_lambda=frequency_lambda,
                severity_shape=severity_shape,
                severity_scale=severity_scale,
                severity_loc=severity_loc,
                confidence_level=confidence_level,
                n_simulations=n_simulations
            )
            
            # Calculate VaR for Event Count
            var_event_count = calculate_event_count_var(
                frequency_lambda=frequency_lambda,
                confidence_level=confidence_level,
                n_simulations=n_simulations
            )
            
            # Append results for each confidence level
            results.append({
                'Year': year,
                'Business Line': business_line,
                'Confidence Level': f"{int(confidence_level * 100)}%",
                'Total Net Loss': total_net_loss,
                'Total Event Count': total_event_count,
                'VaR Net Loss': var_net_loss,
                'VaR Event Count': var_event_count
            })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Display results
print(results_df)
     Year       Business Line Confidence Level  Total Net Loss  \
0    2021  Financial Advisory              99%   -78145.771170   
1    2021  Financial Advisory              95%   -78145.771170   
2    2021  Financial Advisory              90%   -78145.771170   
3    2021   Corporate Banking              99%    99542.018586   
4    2021   Corporate Banking              95%    99542.018586   
..    ...                 ...              ...             ...   
115  2024   Wealth Management              95%   175851.809489   
116  2024   Wealth Management              90%   175851.809489   
117  2024   Corporate Banking              99%   -10575.359749   
118  2024   Corporate Banking              95%   -10575.359749   
119  2024   Corporate Banking              90%   -10575.359749   

     Total Event Count  VaR Net Loss  VaR Event Count  
0                  245  3.520847e+06          295.001  
1                  245  2.433491e+06          271.000  
2                  245  2.177957e+06          265.000  
3                  266  4.051722e+06          318.001  
4                  266  2.645461e+06          292.000  
..                 ...           ...              ...  
115                236  2.584428e+06          261.000  
116                236  2.343328e+06          256.000  
117                259  3.673706e+06          313.001  
118                259  2.583195e+06          286.000  
119                259  2.291295e+06          280.000  

[120 rows x 7 columns]
results_df
Year	Business Line	Confidence Level	Total Net Loss	Total Event Count	VaR Net Loss	VaR Event Count
0	2021	Financial Advisory	99%	-78145.771170	245	3.520847e+06	295.001
1	2021	Financial Advisory	95%	-78145.771170	245	2.433491e+06	271.000
2	2021	Financial Advisory	90%	-78145.771170	245	2.177957e+06	265.000
3	2021	Corporate Banking	99%	99542.018586	266	4.051722e+06	318.001
4	2021	Corporate Banking	95%	99542.018586	266	2.645461e+06	292.000
...	...	...	...	...	...	...	...
115	2024	Wealth Management	95%	175851.809489	236	2.584428e+06	261.000
116	2024	Wealth Management	90%	175851.809489	236	2.343328e+06	256.000
117	2024	Corporate Banking	99%	-10575.359749	259	3.673706e+06	313.001
118	2024	Corporate Banking	95%	-10575.359749	259	2.583195e+06	286.000
119	2024	Corporate Banking	90%	-10575.359749	259	2.291295e+06	280.000
120 rows Ã 7 columns

# To add quarterly results to your calculations, you need to break down the data by quarter and calculate the VaR for each quarter of the year. This can be done by grouping your data based on the quarter within each year.

# Hereâs how you can modify your existing code to calculate the VaR for each quarter of the year for every business line and confidence level:
# import pandas as pd
# import numpy as np
# from scipy.stats import poisson, lognorm

# # Function to calculate VaR for Net Loss using Monte Carlo
# def calculate_net_loss_var(frequency_lambda, severity_shape, severity_scale, severity_loc, confidence_level=0.999, n_simulations=10000):
#     # Simulate event counts (frequency) using Poisson distribution
#     simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
#     # Simulate severity amounts (loss) using Log-Normal distribution
#     simulated_loss_amounts = lognorm.rvs(s=severity_shape, loc=severity_loc, scale=severity_scale, size=n_simulations)
#     # Total losses = frequency * severity
#     total_losses = simulated_event_counts * simulated_loss_amounts
#     # Calculate VaR
#     var_value = np.percentile(total_losses, confidence_level * 100)
#     return var_value

# # Function to calculate VaR for Event Counts using Monte Carlo
# def calculate_event_count_var(frequency_lambda, confidence_level=0.999, n_simulations=10000):
#     # Simulate event counts using Poisson distribution
#     simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
#     # Calculate VaR
#     var_event_count = np.percentile(simulated_event_counts, confidence_level * 100)
#     return var_event_count

# # Prepare results
# results = []

# # Define the confidence levels and number of simulations
# confidence_levels = [0.999, 0.95, 0.90]  # 99%, 95%, and 90%
# n_simulations = 10000

# # Loop through each year, quarter, and business line
# for year in range(2021, 2025):
#     yearly_data = df[df['Year'] == year]
    
#     # Loop over each quarter
#     for quarter in range(1, 5):
#         quarterly_data = yearly_data[yearly_data['Quarter'] == quarter]
        
#         for business_line in quarterly_data['Business Line'].unique():
#             # Filter data for the specific year, quarter, and business line
#             bl_data = quarterly_data[quarterly_data['Business Line'] == business_line]
            
#             # Total event counts and net loss
#             total_event_count = bl_data.shape[0]
#             total_net_loss = bl_data['Net Loss Amount'].sum()
            
#             # Frequency parameter (Poisson Î»)
#             frequency_lambda = total_event_count / 1  # Events per quarter (adjusted)
            
#             # Severity parameters (Log-Normal distribution)
#             positive_losses = bl_data[bl_data['Net Loss Amount'] > 0]['Net Loss Amount']
#             if positive_losses.empty:
#                 print(f"No positive losses for {business_line} in Q{quarter} {year}. Skipping.")
#                 continue
#             severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
            
#             # Calculate VaR for each confidence level
#             for confidence_level in confidence_levels:
#                 var_net_loss = calculate_net_loss_var(
#                     frequency_lambda=frequency_lambda,
#                     severity_shape=severity_shape,
#                     severity_scale=severity_scale,
#                     severity_loc=severity_loc,
#                     confidence_level=confidence_level,
#                     n_simulations=n_simulations
#                 )
                
#                 # Calculate VaR for Event Count
#                 var_event_count = calculate_event_count_var(
#                     frequency_lambda=frequency_lambda,
#                     confidence_level=confidence_level,
#                     n_simulations=n_simulations
#                 )
                
#                 # Append results for each confidence level and quarter
#                 results.append({
#                     'Year': year,
#                     'Quarter': quarter,
#                     'Business Line': business_line,
#                     'Confidence Level': f"{int(confidence_level * 100)}%",
#                     'Total Net Loss': total_net_loss,
#                     'Total Event Count': total_event_count,
#                     'VaR Net Loss': var_net_loss,
#                     'VaR Event Count': var_event_count
#                 })

# # Convert results to DataFrame
# results_df = pd.DataFrame(results)

# # Display results
# print(results_df)
results_df
# Re-importing the necessary libraries
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Function to generate random dates
def random_dates(start, end, n=10):
    return [start + timedelta(days=np.random.randint(0, (end - start).days)) for _ in range(n)]

# Parameters
num_records = 10000
start_date = datetime(2021, 1, 1)
end_date = datetime(2024, 12, 31)

# Generate data with the updated date range
business_lines = [
    "Retail", "Corporate Banking", "Investment Banking", "Insurance",
    "Wealth Management", "Asset Management", "Private Banking",
    "Credit Card Services", "Mortgage Lending", "Financial Advisory"
]

event_types = [
    "Fraud", "System Failure", "Theft", "Compliance", "Natural Disaster",
    "Cyber Attack", "Market Risk", "Operational Error", "Vendor Risk", "Regulatory Violation"
]

data = {
    "Date": random_dates(start_date, end_date, num_records),
    "Unique Event ID": [f"EID{str(i).zfill(5)}" for i in range(num_records)],
    "Event Type": np.random.choice(event_types, num_records),
    "Business Line": np.random.choice(business_lines, num_records),
    "Event Description": np.random.choice(
        [
            "Unauthorized transaction", "Server downtime", "Lost assets", 
            "Regulatory fines", "Data breach", "Network failure", 
            "Inadequate compliance", "Financial misstatement", 
            "Supplier issues", "Internal fraud"
        ],
        num_records
    ),
    "Net Loss Amount": np.random.choice(
        [np.random.uniform(-10000, 0) for _ in range(num_records // 2)] + 
        [np.random.uniform(0, 10000) for _ in range(num_records // 2)],
        num_records
    )
}

# Create DataFrame
df = pd.DataFrame(data)

# Add a Year column
df['Year'] = df['Date'].dt.year

df.head()
Date	Unique Event ID	Event Type	Business Line	Event Description	Net Loss Amount	Year
0	2022-04-09	EID00000	Regulatory Violation	Mortgage Lending	Inadequate compliance	-7353.849221	2022
1	2023-04-17	EID00001	Market Risk	Corporate Banking	Supplier issues	9519.994474	2023
2	2022-10-18	EID00002	System Failure	Mortgage Lending	Network failure	4843.913091	2022
3	2023-12-16	EID00003	Compliance	Asset Management	Unauthorized transaction	-6265.273959	2023
4	2022-01-29	EID00004	Theft	Corporate Banking	Financial misstatement	722.351253	2022
from scipy.stats import poisson, lognorm
import pandas as pd
import numpy as np

# Function to calculate VaR for Net Loss using Monte Carlo
def calculate_net_loss_var(frequency_lambda, severity_shape, severity_scale, severity_loc, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts (frequency) using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Simulate severity amounts (loss) using Log-Normal distribution
    simulated_loss_amounts = lognorm.rvs(s=severity_shape, loc=severity_loc, scale=severity_scale, size=n_simulations)
    # Total losses = frequency * severity
    total_losses = simulated_event_counts * simulated_loss_amounts
    # Calculate VaR
    var_value = np.percentile(total_losses, confidence_level * 100)
    return var_value

# Function to calculate VaR for Event Counts using Monte Carlo
def calculate_event_count_var(frequency_lambda, confidence_level=0.999, n_simulations=10000):
    # Simulate event counts using Poisson distribution
    simulated_event_counts = poisson.rvs(mu=frequency_lambda, size=n_simulations)
    # Calculate VaR
    var_event_count = np.percentile(simulated_event_counts, confidence_level * 100)
    return var_event_count

# Prepare results
results = []

# Define confidence level and number of simulations
confidence_level = 0.999
n_simulations = 10000

# Loop through each year and business line
for year in range(2021, 2025):
    yearly_data = df[df['Year'] == year]
    
    for business_line in yearly_data['Business Line'].unique():
        # Filter data for the specific year and business line
        bl_data = yearly_data[yearly_data['Business Line'] == business_line]
        
        # Total event counts and net loss
        total_event_count = bl_data.shape[0]
        total_net_loss = bl_data['Net Loss Amount'].sum()
        
        # Frequency parameter (Poisson Î»)
        frequency_lambda = total_event_count / 1  # Events per year
        
        # Severity parameters (Log-Normal distribution)
        positive_losses = bl_data[bl_data['Net Loss Amount'] > 0]['Net Loss Amount']
        if positive_losses.empty:
            print(f"No positive losses for {business_line} in {year}. Skipping.")
            continue
        severity_shape, severity_loc, severity_scale = lognorm.fit(positive_losses)
        
        # Calculate VaR for Net Loss
        var_net_loss = calculate_net_loss_var(
            frequency_lambda=frequency_lambda,
            severity_shape=severity_shape,
            severity_scale=severity_scale,
            severity_loc=severity_loc,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Calculate VaR for Event Count
        var_event_count = calculate_event_count_var(
            frequency_lambda=frequency_lambda,
            confidence_level=confidence_level,
            n_simulations=n_simulations
        )
        
        # Append results
        results.append({
            'Year': year,
            'Business Line': business_line,
            'Total Net Loss': total_net_loss,
            'Total Event Count': total_event_count,
            'VaR Net Loss (99.9%)': var_net_loss,
            'VaR Event Count (99.9%)': var_event_count
        })

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Display results
print(results_df)
    Year         Business Line  Total Net Loss  Total Event Count  \
0   2021     Wealth Management   -22767.658817                263   
1   2021      Asset Management   -46549.908412                257   
2   2021    Investment Banking   -47131.331137                256   
3   2021                Retail   -28582.851080                247   
4   2021     Corporate Banking     5822.830437                273   
5   2021             Insurance   -77058.045832                262   
6   2021  Credit Card Services   -12171.590194                236   
7   2021    Financial Advisory  -241348.814240                234   
8   2021       Private Banking   104924.802571                235   
9   2021      Mortgage Lending     9392.768262                252   
10  2022      Mortgage Lending    77996.394803                256   
11  2022     Corporate Banking   -34067.426127                240   
12  2022      Asset Management   -86347.100405                247   
13  2022       Private Banking    74951.599156                294   
14  2022                Retail     3094.323027                273   
15  2022  Credit Card Services   -36026.252392                242   
16  2022    Investment Banking    22268.785277                237   
17  2022    Financial Advisory  -130572.085013                242   
18  2022             Insurance   -70659.162315                237   
19  2022     Wealth Management   133989.672706                224   
20  2023     Corporate Banking    84749.049533                250   
21  2023      Asset Management   154395.833816                233   
22  2023    Investment Banking   192256.079265                243   
23  2023    Financial Advisory    63604.346561                211   
24  2023     Wealth Management    88152.802027                259   
25  2023       Private Banking   -63335.641328                268   
26  2023             Insurance    24871.675509                261   
27  2023  Credit Card Services   -53260.974612                271   
28  2023      Mortgage Lending  -132530.855515                261   
29  2023                Retail   -31083.656423                214   
30  2024     Corporate Banking    76967.014434                256   
31  2024  Credit Card Services   -43965.969843                245   
32  2024             Insurance    17272.426247                247   
33  2024                Retail    27333.652498                262   
34  2024       Private Banking   -68967.898844                252   
35  2024    Financial Advisory  -102250.811340                242   
36  2024     Wealth Management   182743.802791                245   
37  2024    Investment Banking     7289.797174                233   
38  2024      Mortgage Lending   227658.239327                280   
39  2024      Asset Management   -64287.765253                260   

    VaR Net Loss (99.9%)  VaR Event Count (99.9%)  
0           3.962409e+06                  311.001  
1           4.202935e+06                  308.000  
2           4.554776e+06                  306.001  
3           3.794744e+06                  294.000  
4           3.893127e+06                  324.000  
5           3.792837e+06                  313.000  
6           3.691367e+06                  285.001  
7           3.420330e+06                  283.000  
8           3.708299e+06                  284.001  
9           3.709708e+06                  300.000  
10          3.782368e+06                  304.001  
11          4.358171e+06                  290.000  
12          3.977700e+06                  300.000  
13          4.196594e+06                  350.000  
14          3.843179e+06                  326.000  
15          3.258750e+06                  295.000  
16          3.539322e+06                  285.001  
17          6.148991e+06                  289.000  
18          3.219398e+06                  286.002  
19          3.299116e+06                  270.001  
20          3.534543e+06                  300.000  
21          3.380150e+06                  284.000  
22          3.645663e+06                  294.000  
23          3.204110e+06                  256.000  
24          3.820351e+06                  310.000  
25          3.548482e+06                  319.001  
26          3.528827e+06                  310.002  
27          3.845817e+06                  326.000  
28          4.297870e+06                  313.000  
29          3.174698e+06                  260.000  
30          3.522896e+06                  304.000  
31          3.788623e+06                  293.000  
32          3.887151e+06                  297.000  
33          3.482968e+06                  312.000  
34          3.808684e+06                  300.001  
35          3.436577e+06                  294.000  
36          3.489305e+06                  293.001  
37          3.410293e+06                  281.000  
38          3.968033e+06                  335.000  
39          3.499070e+06                  312.000  
results_df
Year	Business Line	Total Net Loss	Total Event Count	VaR Net Loss (99.9%)	VaR Event Count (99.9%)
0	2021	Wealth Management	-22767.658817	263	3.962409e+06	311.001
1	2021	Asset Management	-46549.908412	257	4.202935e+06	308.000
2	2021	Investment Banking	-47131.331137	256	4.554776e+06	306.001
3	2021	Retail	-28582.851080	247	3.794744e+06	294.000
4	2021	Corporate Banking	5822.830437	273	3.893127e+06	324.000
5	2021	Insurance	-77058.045832	262	3.792837e+06	313.000
6	2021	Credit Card Services	-12171.590194	236	3.691367e+06	285.001
7	2021	Financial Advisory	-241348.814240	234	3.420330e+06	283.000
8	2021	Private Banking	104924.802571	235	3.708299e+06	284.001
9	2021	Mortgage Lending	9392.768262	252	3.709708e+06	300.000
10	2022	Mortgage Lending	77996.394803	256	3.782368e+06	304.001
11	2022	Corporate Banking	-34067.426127	240	4.358171e+06	290.000
12	2022	Asset Management	-86347.100405	247	3.977700e+06	300.000
13	2022	Private Banking	74951.599156	294	4.196594e+06	350.000
14	2022	Retail	3094.323027	273	3.843179e+06	326.000
15	2022	Credit Card Services	-36026.252392	242	3.258750e+06	295.000
16	2022	Investment Banking	22268.785277	237	3.539322e+06	285.001
17	2022	Financial Advisory	-130572.085013	242	6.148991e+06	289.000
18	2022	Insurance	-70659.162315	237	3.219398e+06	286.002
19	2022	Wealth Management	133989.672706	224	3.299116e+06	270.001
20	2023	Corporate Banking	84749.049533	250	3.534543e+06	300.000
21	2023	Asset Management	154395.833816	233	3.380150e+06	284.000
22	2023	Investment Banking	192256.079265	243	3.645663e+06	294.000
23	2023	Financial Advisory	63604.346561	211	3.204110e+06	256.000
24	2023	Wealth Management	88152.802027	259	3.820351e+06	310.000
25	2023	Private Banking	-63335.641328	268	3.548482e+06	319.001
26	2023	Insurance	24871.675509	261	3.528827e+06	310.002
27	2023	Credit Card Services	-53260.974612	271	3.845817e+06	326.000
28	2023	Mortgage Lending	-132530.855515	261	4.297870e+06	313.000
29	2023	Retail	-31083.656423	214	3.174698e+06	260.000
30	2024	Corporate Banking	76967.014434	256	3.522896e+06	304.000
31	2024	Credit Card Services	-43965.969843	245	3.788623e+06	293.000
32	2024	Insurance	17272.426247	247	3.887151e+06	297.000
33	2024	Retail	27333.652498	262	3.482968e+06	312.000
34	2024	Private Banking	-68967.898844	252	3.808684e+06	300.001
35	2024	Financial Advisory	-102250.811340	242	3.436577e+06	294.000
36	2024	Wealth Management	182743.802791	245	3.489305e+06	293.001
37	2024	Investment Banking	7289.797174	233	3.410293e+06	281.000
38	2024	Mortgage Lending	227658.239327	280	3.968033e+06	335.000
39	2024	Asset Management	-64287.765253	260	3.499070e+06	312.000
# Aggregate data for total event counts and net loss per year, per business line
aggregated_data_bl = df.groupby(['Year', 'Business Line']).agg(
    total_event_count=('Unique Event ID', 'count'),
    total_net_loss=('Net Loss Amount', 'sum')
).reset_index()

# Display the aggregated data for a specific business line (e.g., Retail)
aggregated_data_bl[aggregated_data_bl['Business Line'] == 'Retail']
Year	Business Line	total_event_count	total_net_loss
8	2021	Retail	247	-28582.851080
18	2022	Retail	273	3094.323027
28	2023	Retail	214	-31083.656423
38	2024	Retail	262	27333.652498
# Import necessary libraries
from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Function to fit ARIMA model and forecast for the next year for each business line
def forecast_arima(data, steps=1):
    model = ARIMA(data, order=(1, 1, 1))  # (p, d, q) - can be adjusted based on performance
    model_fit = model.fit()
    forecast = model_fit.forecast(steps=steps)
    return forecast

# Aggregate data for total event counts and net loss per year, per business line
aggregated_data_bl = df.groupby(['Year', 'Business Line']).agg(
    total_event_count=('Unique Event ID', 'count'),
    total_net_loss=('Net Loss Amount', 'sum')
).reset_index()

# Store results for all business lines
forecast_results = []

# Loop through each business line
for business_line in aggregated_data_bl['Business Line'].unique():
    # Filter data for the current business line
    bl_data = aggregated_data_bl[aggregated_data_bl['Business Line'] == business_line]
    
    # Forecast for Event Counts and Net Loss for 2025
    event_counts_forecast = forecast_arima(bl_data['total_event_count'])
    net_loss_forecast = forecast_arima(bl_data['total_net_loss'])
    
    # Ensure that forecast values are accessible
    predicted_event_count = event_counts_forecast[0] if len(event_counts_forecast) > 0 else np.nan
    predicted_net_loss = net_loss_forecast[0] if len(net_loss_forecast) > 0 else np.nan

    # Add actual data for years 2021-2024, and set NaN for 2025
    for year in [2021, 2022, 2023, 2024]:
        total_event_count = bl_data[bl_data['Year'] == year]['total_event_count'].values[0] if year in bl_data['Year'].values else np.nan
        total_net_loss = bl_data[bl_data['Year'] == year]['total_net_loss'].values[0] if year in bl_data['Year'].values else np.nan
        
        forecast_results.append({
            'Year': year,
            'Business Line': business_line,
            'Total Net Loss': total_net_loss,
            'Total Event Count': total_event_count,
            'Predicted Net Loss for 2025': np.nan,
            'Predicted Event Count for 2025': np.nan
        })
    
    # Append predicted data for 2025
    forecast_results.append({
        'Year': 2025,
        'Business Line': business_line,
        'Total Net Loss': np.nan,
        'Total Event Count': np.nan,
        'Predicted Net Loss for 2025': predicted_net_loss,
        'Predicted Event Count for 2025': predicted_event_count
    })

# Convert results to DataFrame
forecast_df = pd.DataFrame(forecast_results)

# Display the forecasted values
print(forecast_df)

# Plotting the predictions for each business line
plt.figure(figsize=(14, 8))

# Loop through each business line and plot its forecast
for idx, row in forecast_df.iterrows():
    if row['Year'] == 2025:  # Only plot predictions for 2025
        plt.plot([2024, 2025], 
                 [aggregated_data_bl[aggregated_data_bl['Business Line'] == row['Business Line']]['total_event_count'].iloc[-1], row['Predicted Event Count for 2025']], 
                 marker='o', label=f"Event Count - {row['Business Line']}")
        plt.plot([2024, 2025], 
                 [aggregated_data_bl[aggregated_data_bl['Business Line'] == row['Business Line']]['total_net_loss'].iloc[-1], row['Predicted Net Loss for 2025']], 
                 marker='x', label=f"Net Loss - {row['Business Line']}")

plt.title('Predictions for Event Counts and Net Loss for 2025 by Business Line')
plt.xlabel('Year')
plt.ylabel('Value')
plt.legend(loc='best')
plt.grid(True)
plt.show()
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\statespace\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.
  warn('Too few observations to estimate starting parameters%s.'
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.
  return get_prediction_index(
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.
  return get_prediction_index(
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.
  self._init_dates(dates, freq)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\statespace\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.
  warn('Too few observations to estimate starting parameters%s.'
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.
  return get_prediction_index(
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\base\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.
  return get_prediction_index(
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\indexes\range.py:413, in RangeIndex.get_loc(self, key)
    412 try:
--> 413     return self._range.index(new_key)
    414 except ValueError as err:

ValueError: 0 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[41], line 33
     30 net_loss_forecast = forecast_arima(bl_data['total_net_loss'])
     32 # Ensure that forecast values are accessible
---> 33 predicted_event_count = event_counts_forecast[0] if len(event_counts_forecast) > 0 else np.nan
     34 predicted_net_loss = net_loss_forecast[0] if len(net_loss_forecast) > 0 else np.nan
     36 # Add actual data for years 2021-2024, and set NaN for 2025

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py:1121, in Series.__getitem__(self, key)
   1118     return self._values[key]
   1120 elif key_is_scalar:
-> 1121     return self._get_value(key)
   1123 # Convert generator to list before going through hashable part
   1124 # (We will iterate through the generator there to check for slices)
   1125 if is_iterator(key):

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py:1237, in Series._get_value(self, label, takeable)
   1234     return self._values[label]
   1236 # Similar to Index.get_value, but we do not fall back to positional
-> 1237 loc = self.index.get_loc(label)
   1239 if is_integer(loc):
   1240     return self._values[loc]

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\indexes\range.py:415, in RangeIndex.get_loc(self, key)
    413         return self._range.index(new_key)
    414     except ValueError as err:
--> 415         raise KeyError(key) from err
    416 if isinstance(key, Hashable):
    417     raise KeyError(key)

KeyError: 0
import numpy as np
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

# Sample data preparation (Replace with your actual dataset)
data = {
    'year': [2021, 2022, 2023, 2024],
    'total_net_loss': [100, 150, 200, 250],
    'event_count': [10, 15, 20, 25]
}

# Create a DataFrame
bl_data = pd.DataFrame(data)

# Function for ARIMA forecasting
def forecast_arima(data, steps=1):
    model = ARIMA(data, order=(1, 1, 1))  # You can modify the ARIMA order based on your needs
    model_fit = model.fit()
    forecast = model_fit.forecast(steps=steps)
    return forecast

# Forecasting total net loss and event count for 2025
net_loss_forecast = forecast_arima(bl_data['total_net_loss'])
event_counts_forecast = forecast_arima(bl_data['event_count'])

# Debugging: Check the forecast output
print(f"Net Loss Forecast: {net_loss_forecast}")
print(f"Event Count Forecast: {event_counts_forecast}")

# Ensuring proper indexing for forecasted values
predicted_event_count = event_counts_forecast[0] if len(event_counts_forecast) > 0 else np.nan
predicted_net_loss = net_loss_forecast[0] if len(net_loss_forecast) > 0 else np.nan

# Prepare the forecast results for 2025
forecast_results = []
for year in [2021, 2022, 2023, 2024]:
    forecast_results.append({
        'Year': year,
        'Business Line': 'Sample Business Line',  # Adjust according to your data
        'Total Net Loss': bl_data.loc[bl_data['year'] == year, 'total_net_loss'].values[0],
        'Total Event Count': bl_data.loc[bl_data['year'] == year, 'event_count'].values[0],
        'Predicted Net Loss for 2025': np.nan,
        'Predicted Event Count for 2025': np.nan
    })

# Add actual data for 2025
forecast_results.append({
    'Year': 2025,
    'Business Line': 'Sample Business Line',
    'Total Net Loss': np.nan,
    'Total Event Count': np.nan,
    'Predicted Net Loss for 2025': predicted_net_loss,
    'Predicted Event Count for 2025': predicted_event_count
})

# Convert results to DataFrame
forecast_df = pd.DataFrame(forecast_results)

# Display the forecast DataFrame
print(forecast_df)
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\statespace\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.
  warn('Too few observations to estimate starting parameters%s.'
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\tsa\statespace\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.
  warn('Too few observations to estimate starting parameters%s.'
Net Loss Forecast: 4    299.970146
dtype: float64
Event Count Forecast: 4    29.999815
dtype: float64
C:\Users\Himanshu Singh\AppData\Local\Programs\Python\Python312\Lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals
  warnings.warn("Maximum Likelihood optimization failed to "
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\indexes\range.py:413, in RangeIndex.get_loc(self, key)
    412 try:
--> 413     return self._range.index(new_key)
    414 except ValueError as err:

ValueError: 0 is not in range

The above exception was the direct cause of the following exception:

KeyError                                  Traceback (most recent call last)
Cell In[42], line 31
     28 print(f"Event Count Forecast: {event_counts_forecast}")
     30 # Ensuring proper indexing for forecasted values
---> 31 predicted_event_count = event_counts_forecast[0] if len(event_counts_forecast) > 0 else np.nan
     32 predicted_net_loss = net_loss_forecast[0] if len(net_loss_forecast) > 0 else np.nan
     34 # Prepare the forecast results for 2025

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py:1121, in Series.__getitem__(self, key)
   1118     return self._values[key]
   1120 elif key_is_scalar:
-> 1121     return self._get_value(key)
   1123 # Convert generator to list before going through hashable part
   1124 # (We will iterate through the generator there to check for slices)
   1125 if is_iterator(key):

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\series.py:1237, in Series._get_value(self, label, takeable)
   1234     return self._values[label]
   1236 # Similar to Index.get_value, but we do not fall back to positional
-> 1237 loc = self.index.get_loc(label)
   1239 if is_integer(loc):
   1240     return self._values[loc]

File ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\pandas\core\indexes\range.py:415, in RangeIndex.get_loc(self, key)
    413         return self._range.index(new_key)
    414     except ValueError as err:
--> 415         raise KeyError(key) from err
    416 if isinstance(key, Hashable):
    417     raise KeyError(key)

KeyError: 0
 
 
 
 
 
 
 
import pandas as pd
import numpy as np
from scipy import stats

# Assuming 'df' is the DataFrame already created as provided in the example.

# Step 1: Add Quarter and Year columns to df
df['Year'] = df['Date'].dt.year
df['Quarter'] = df['Date'].dt.to_period('Q')

# Step 2: Calculate the average event count per business line, quarter, and event type from 2020 to 2024
event_count_avg_2020_2024 = df[df['Year'] < 2025].groupby(['Business Line', 'Quarter']).agg(
    Event_Count_Avg=('Unique Event ID', 'count')  # Count the number of Unique Event IDs for each Business Line and Quarter
).reset_index()

# Step 3: Fit a log-normal distribution to the historical losses (negative net loss amounts only)
negative_losses = df[df['Net Loss Amount'] < 0]
shape, loc, scale = stats.lognorm.fit(negative_losses['Net Loss Amount'] * -1)

# Step 4: Simulate future losses (for 2025) for each business line and quarter using the fitted distribution
n_simulations = 10000  # Simulate 10,000 possible losses for each business line and quarter
simulated_losses = {}

for business_line in event_count_avg_2020_2024['Business Line'].unique():
    for quarter in event_count_avg_2020_2024['Quarter'].unique():
        # Simulate future losses for the business line and quarter
        simulated_losses[(business_line, quarter)] = stats.lognorm.rvs(s=shape, loc=loc, scale=scale, size=(n_simulations))

# Step 5: Calculate VaR (99.9%) and total predicted losses for 2025 for each quarter
confidence = 0.999  # 99.9% confidence level for VaR
var_results_2025 = []

for business_line, quarter in simulated_losses.keys():
    losses = simulated_losses[(business_line, quarter)]
    var_99_9 = np.percentile(losses, (1 - confidence) * 100)  # Calculate VaR at 99.9% confidence level
    event_count = event_count_avg_2020_2024[(event_count_avg_2020_2024['Business Line'] == business_line) & 
                                            (event_count_avg_2020_2024['Quarter'] == quarter)]['Event_Count_Avg'].iloc[0]
    total_loss = losses.sum()  # Sum of simulated losses for the quarter

    var_results_2025.append({
        'Year': 2025,
        'Quarter': str(quarter),
        'Business Line': business_line,
        'Predicted Event Count': event_count,
        'Total Predicted Loss Amount': total_loss,
        'VaR (99.9%)': var_99_9
    })

# Step 6: Convert the results into a DataFrame
var_df_2025 = pd.DataFrame(var_results_2025)

# Step 7: Display the prediction results for 2025
print(var_df_2025)
     Year Quarter      Business Line  Predicted Event Count  \
0    2025  2020Q4   Asset Management                     31   
1    2025  2021Q1   Asset Management                     50   
2    2025  2021Q2   Asset Management                     60   
3    2025  2021Q3   Asset Management                     78   
4    2025  2021Q4   Asset Management                     56   
..    ...     ...                ...                    ...   
165  2025  2023Q4  Wealth Management                     60   
166  2025  2024Q1  Wealth Management                     56   
167  2025  2024Q2  Wealth Management                     64   
168  2025  2024Q3  Wealth Management                     52   
169  2025  2024Q4  Wealth Management                     26   

     Total Predicted Loss Amount  VaR (99.9%)  
0                   4.986208e+07 -3770.013967  
1                   4.915997e+07 -3747.159291  
2                   5.039861e+07 -4006.028941  
3                   5.029549e+07 -4051.264763  
4                   5.003968e+07 -4060.814830  
..                           ...          ...  
165                 4.987089e+07 -3968.743244  
166                 4.994855e+07 -4033.926777  
167                 5.012272e+07 -4498.526327  
168                 4.991885e+07 -3587.432252  
169                 4.988499e+07 -3695.182770  

[170 rows x 6 columns]
var_df_2025
Year	Quarter	Business Line	Predicted Event Count	Total Predicted Loss Amount	VaR (99.9%)
0	2025	2020Q4	Asset Management	31	4.986208e+07	-3770.013967
1	2025	2021Q1	Asset Management	50	4.915997e+07	-3747.159291
2	2025	2021Q2	Asset Management	60	5.039861e+07	-4006.028941
3	2025	2021Q3	Asset Management	78	5.029549e+07	-4051.264763
4	2025	2021Q4	Asset Management	56	5.003968e+07	-4060.814830
...	...	...	...	...	...	...
165	2025	2023Q4	Wealth Management	60	4.987089e+07	-3968.743244
166	2025	2024Q1	Wealth Management	56	4.994855e+07	-4033.926777
167	2025	2024Q2	Wealth Management	64	5.012272e+07	-4498.526327
168	2025	2024Q3	Wealth Management	52	4.991885e+07	-3587.432252
169	2025	2024Q4	Wealth Management	26	4.988499e+07	-3695.182770
170 rows Ã 6 columns

import pandas as pd
import numpy as np
from scipy import stats

# Assuming df is the DataFrame with 'Net Loss Amount' column
n_simulations = 10000  # Number of simulations for Monte Carlo
confidence_level = 0.999  # 99.9% confidence level for VaR

# Assuming event_count_avg_2020_2024 is already calculated as per previous steps
# and df has columns 'Business Line', 'Event Type', 'Net Loss Amount', and 'Year'

# Step 1: Simulate future event counts for 2025 (using historical averages)
event_count_avg_2020_2024 = df[df['Year'] < 2025].groupby(['Business Line', 'Event Type']).agg(
    Event_Count_Avg=('Unique Event ID', 'count')  # Counting the number of events for each business line and event type
).reset_index()

# Step 2: Handle negative and positive losses for log-normal fitting
negative_losses = df[df['Net Loss Amount'] < 0]
if negative_losses.empty:
    print("No negative losses found in the data. Proceeding with positive losses.")
    positive_losses = df[df['Net Loss Amount'] > 0]
    shape, loc, scale = stats.lognorm.fit(positive_losses['Net Loss Amount'])
else:
    shape, loc, scale = stats.lognorm.fit(negative_losses['Net Loss Amount'] * -1)

# Step 3: Simulate future losses for 2025
simulated_losses = {}
simulated_event_counts = {}

for business_line in event_count_avg_2020_2024['Business Line'].unique():
    # Simulate event counts based on historical event count averages (using Poisson distribution)
    event_count = event_count_avg_2020_2024[event_count_avg_2020_2024['Business Line'] == business_line]['Event_Count_Avg'].iloc[0]
    simulated_event_counts[business_line] = np.random.poisson(lam=event_count, size=n_simulations)
    
    # Simulate losses using the fitted log-normal distribution
    simulated_losses[business_line] = stats.lognorm.rvs(s=shape, loc=loc, scale=scale, size=n_simulations)

# Step 4: Calculate VaR (99.9%) for Event Counts and Net Loss Amounts
var_results_2025 = {}

for business_line in simulated_losses.keys():
    # Calculate VaR for Event Count (99.9% confidence)
    var_event_count_99_9 = np.percentile(simulated_event_counts[business_line], (1 - confidence_level) * 100)
    
    # Calculate VaR for Net Loss (99.9% confidence)
    var_loss_99_9 = np.percentile(simulated_losses[business_line], (1 - confidence_level) * 100)
    
    # Calculate total predicted event count and total predicted net loss
    predicted_event_count = simulated_event_counts[business_line].mean()  # Mean event count for prediction
    predicted_net_loss = simulated_losses[business_line].sum()  # Sum of simulated losses for net loss prediction
    
    var_results_2025[business_line] = {
        'Year': 2025,
        'Business Line': business_line,
        'Predicted Event Count': predicted_event_count,
        'Predicted Net Loss': predicted_net_loss,
        'VaR Event Count (99.9%)': var_event_count_99_9,
        'VaR Net Loss (99.9%)': var_loss_99_9
    }

# Step 5: Convert the results into a DataFrame
var_df_2025 = pd.DataFrame(var_results_2025).T

# Step 6: Display the prediction results for 2025
print(var_df_2025)
                      Year         Business Line Predicted Event Count  \
Asset Management      2025      Asset Management                88.151   
Corporate Banking     2025     Corporate Banking              101.9215   
Credit Card Services  2025  Credit Card Services               99.0139   
Financial Advisory    2025    Financial Advisory              101.9995   
Insurance             2025             Insurance                101.06   
Investment Banking    2025    Investment Banking               91.7822   
Mortgage Lending      2025      Mortgage Lending               77.9167   
Private Banking       2025       Private Banking               91.1207   
Retail                2025                Retail               92.0362   
Wealth Management     2025     Wealth Management                97.977   

                     Predicted Net Loss VaR Event Count (99.9%)  \
Asset Management        49995044.513459                    60.0   
Corporate Banking       50181031.756789                    72.0   
Credit Card Services    49956326.649471                    71.0   
Financial Advisory      50007220.076223                    73.0   
Insurance                50273413.94665                    71.0   
Investment Banking      49992159.240847                  63.999   
Mortgage Lending        50393162.396574                    52.0   
Private Banking         49797454.082535                    64.0   
Retail                  49763575.282917                    64.0   
Wealth Management         49743025.5171                    68.0   

                     VaR Net Loss (99.9%)  
Asset Management             -3556.010454  
Corporate Banking            -4019.397481  
Credit Card Services         -3335.710031  
Financial Advisory           -3774.310817  
Insurance                    -4125.167813  
Investment Banking           -3957.329617  
Mortgage Lending             -3532.368749  
Private Banking              -4183.540039  
Retail                       -4034.636842  
Wealth Management             -3996.03528  
var_df_2025
Year	Business Line	Predicted Event Count	Predicted Net Loss	VaR Event Count (99.9%)	VaR Net Loss (99.9%)
Asset Management	2025	Asset Management	88.151	49995044.513459	60.0	-3556.010454
Corporate Banking	2025	Corporate Banking	101.9215	50181031.756789	72.0	-4019.397481
Credit Card Services	2025	Credit Card Services	99.0139	49956326.649471	71.0	-3335.710031
Financial Advisory	2025	Financial Advisory	101.9995	50007220.076223	73.0	-3774.310817
Insurance	2025	Insurance	101.06	50273413.94665	71.0	-4125.167813
Investment Banking	2025	Investment Banking	91.7822	49992159.240847	63.999	-3957.329617
Mortgage Lending	2025	Mortgage Lending	77.9167	50393162.396574	52.0	-3532.368749
Private Banking	2025	Private Banking	91.1207	49797454.082535	64.0	-4183.540039
Retail	2025	Retail	92.0362	49763575.282917	64.0	-4034.636842
Wealth Management	2025	Wealth Management	97.977	49743025.5171	68.0	-3996.03528
import pandas as pd
import numpy as np
from scipy import stats

# Assuming df is the DataFrame with 'Net Loss Amount' column
n_simulations = 10000  # Number of simulations for Monte Carlo
confidence_level = 0.999  # 99.9% confidence level for VaR

# Step 1: Simulate future event counts for 2025 (using historical averages)
event_count_avg_2020_2024 = df[df['Year'] < 2025].groupby(['Business Line', 'Event Type']).agg(
    Event_Count_Avg=('Unique Event ID', 'count')  # Counting the number of events for each business line and event type
).reset_index()

# Step 2: Handle negative and positive losses for log-normal fitting
negative_losses = df[df['Net Loss Amount'] < 0]
if negative_losses.empty:
    print("No negative losses found in the data. Proceeding with positive losses.")
    positive_losses = df[df['Net Loss Amount'] > 0]
    shape, loc, scale = stats.lognorm.fit(positive_losses['Net Loss Amount'])
else:
    shape, loc, scale = stats.lognorm.fit(negative_losses['Net Loss Amount'] * -1)

# Step 3: Simulate future losses for 2025 (quarterly)
simulated_losses = {}
simulated_event_counts = {}

quarters = ['Q1', 'Q2', 'Q3', 'Q4']
for quarter in quarters:
    simulated_losses[quarter] = {}
    simulated_event_counts[quarter] = {}
    
    for business_line in event_count_avg_2020_2024['Business Line'].unique():
        # Simulate event counts based on historical event count averages (using Poisson distribution)
        event_count = event_count_avg_2020_2024[event_count_avg_2020_2024['Business Line'] == business_line]['Event_Count_Avg'].iloc[0]
        simulated_event_counts[quarter][business_line] = np.random.poisson(lam=event_count, size=n_simulations)
        
        # Simulate losses using the fitted log-normal distribution
        simulated_losses[quarter][business_line] = stats.lognorm.rvs(s=shape, loc=loc, scale=scale, size=n_simulations)

# Step 4: Calculate VaR (99.9%) for Event Counts and Net Loss Amounts (quarterly)
var_results_2025 = []

for quarter in quarters:
    for business_line in simulated_losses[quarter].keys():
        # Calculate VaR for Event Count (99.9% confidence)
        var_event_count_99_9 = np.percentile(simulated_event_counts[quarter][business_line], (1 - confidence_level) * 100)
        
        # Calculate VaR for Net Loss (99.9% confidence)
        var_loss_99_9 = np.percentile(simulated_losses[quarter][business_line], (1 - confidence_level) * 100)
        
        # Calculate total predicted event count and total predicted net loss
        predicted_event_count = simulated_event_counts[quarter][business_line].mean()  # Mean event count for prediction
        predicted_net_loss = simulated_losses[quarter][business_line].sum()  # Sum of simulated losses for net loss prediction
        
        # Store results
        var_results_2025.append({
            'Year': 2025,
            'Quarter': quarter,
            'Business Line': business_line,
            'Predicted Event Count': predicted_event_count,
            'Predicted Net Loss': predicted_net_loss,
            'VaR Event Count (99.9%)': var_event_count_99_9,
            'VaR Net Loss (99.9%)': var_loss_99_9
        })

# Step 5: Convert the results into a DataFrame
var_df_2025 = pd.DataFrame(var_results_2025)

# Step 6: Display the prediction results for 2025
print(var_df_2025)
    Year Quarter         Business Line  Predicted Event Count  \
0   2025      Q1      Asset Management                87.9161   
1   2025      Q1     Corporate Banking               102.0186   
2   2025      Q1  Credit Card Services                98.9267   
3   2025      Q1    Financial Advisory               102.0044   
4   2025      Q1             Insurance               101.0295   
5   2025      Q1    Investment Banking                92.0628   
6   2025      Q1      Mortgage Lending                78.0763   
7   2025      Q1       Private Banking                91.0277   
8   2025      Q1                Retail                91.9467   
9   2025      Q1     Wealth Management                97.9734   
10  2025      Q2      Asset Management                88.0131   
11  2025      Q2     Corporate Banking               101.9372   
12  2025      Q2  Credit Card Services                99.0101   
13  2025      Q2    Financial Advisory               101.9666   
14  2025      Q2             Insurance               100.9409   
15  2025      Q2    Investment Banking                92.0268   
16  2025      Q2      Mortgage Lending                78.0187   
17  2025      Q2       Private Banking                90.9463   
18  2025      Q2                Retail                91.8694   
19  2025      Q2     Wealth Management                97.9966   
20  2025      Q3      Asset Management                87.8872   
21  2025      Q3     Corporate Banking               102.0721   
22  2025      Q3  Credit Card Services                99.2171   
23  2025      Q3    Financial Advisory               101.8237   
24  2025      Q3             Insurance               101.0239   
25  2025      Q3    Investment Banking                92.0232   
26  2025      Q3      Mortgage Lending                77.9528   
27  2025      Q3       Private Banking                90.9557   
28  2025      Q3                Retail                92.0308   
29  2025      Q3     Wealth Management                98.1530   
30  2025      Q4      Asset Management                88.0615   
31  2025      Q4     Corporate Banking               102.2616   
32  2025      Q4  Credit Card Services                98.6295   
33  2025      Q4    Financial Advisory               102.0310   
34  2025      Q4             Insurance               101.1266   
35  2025      Q4    Investment Banking                92.0569   
36  2025      Q4      Mortgage Lending                77.9845   
37  2025      Q4       Private Banking                90.8208   
38  2025      Q4                Retail                92.1605   
39  2025      Q4     Wealth Management                98.1442   

    Predicted Net Loss  VaR Event Count (99.9%)  VaR Net Loss (99.9%)  
0         5.030451e+07                   61.000          -3515.101768  
1         4.968461e+07                   72.000          -3726.038428  
2         4.971821e+07                   72.000          -4315.690430  
3         5.023523e+07                   70.000          -3731.068849  
4         4.979646e+07                   71.000          -3902.240653  
5         5.041847e+07                   63.999          -3879.526928  
6         4.959514e+07                   52.999          -4110.470609  
7         5.015740e+07                   63.999          -3492.462545  
8         5.015619e+07                   63.999          -3756.013947  
9         5.059234e+07                   67.000          -3341.015210  
10        4.980141e+07                   60.000          -3763.325512  
11        4.919203e+07                   71.000          -3767.300844  
12        4.980885e+07                   70.999          -3999.316319  
13        4.990778e+07                   73.000          -3919.582914  
14        5.020819e+07                   71.000          -3720.728505  
15        4.974280e+07                   62.999          -3890.210261  
16        4.982490e+07                   52.000          -3527.646461  
17        4.994254e+07                   63.000          -4128.131603  
18        4.996057e+07                   64.000          -3547.024011  
19        4.977632e+07                   69.000          -3597.750233  
20        5.012981e+07                   61.000          -3992.447626  
21        4.970278e+07                   73.000          -3924.206637  
22        5.022994e+07                   71.000          -3757.128131  
23        4.972240e+07                   73.000          -4092.111129  
24        4.980472e+07                   70.999          -3453.958637  
25        4.918884e+07                   65.000          -4039.358826  
26        4.993892e+07                   52.000          -4038.651527  
27        4.997236e+07                   63.000          -3703.703319  
28        5.026834e+07                   64.999          -4348.077725  
29        5.038173e+07                   69.000          -4013.622147  
30        5.029675e+07                   60.000          -3796.948589  
31        4.956477e+07                   73.000          -3816.070640  
32        5.032075e+07                   69.000          -3992.280462  
33        4.987629e+07                   72.999          -3759.774755  
34        4.932392e+07                   71.000          -4091.838325  
35        5.000784e+07                   64.000          -3876.229322  
36        4.987193e+07                   52.999          -4288.005978  
37        4.982658e+07                   64.000          -3692.783527  
38        4.987856e+07                   64.000          -4365.141808  
39        4.986036e+07                   69.998          -4224.706032  
var_df_2025
Year	Quarter	Business Line	Predicted Event Count	Predicted Net Loss	VaR Event Count (99.9%)	VaR Net Loss (99.9%)
0	2025	Q1	Asset Management	87.9161	5.030451e+07	61.000	-3515.101768
1	2025	Q1	Corporate Banking	102.0186	4.968461e+07	72.000	-3726.038428
2	2025	Q1	Credit Card Services	98.9267	4.971821e+07	72.000	-4315.690430
3	2025	Q1	Financial Advisory	102.0044	5.023523e+07	70.000	-3731.068849
4	2025	Q1	Insurance	101.0295	4.979646e+07	71.000	-3902.240653
5	2025	Q1	Investment Banking	92.0628	5.041847e+07	63.999	-3879.526928
6	2025	Q1	Mortgage Lending	78.0763	4.959514e+07	52.999	-4110.470609
7	2025	Q1	Private Banking	91.0277	5.015740e+07	63.999	-3492.462545
8	2025	Q1	Retail	91.9467	5.015619e+07	63.999	-3756.013947
9	2025	Q1	Wealth Management	97.9734	5.059234e+07	67.000	-3341.015210
10	2025	Q2	Asset Management	88.0131	4.980141e+07	60.000	-3763.325512
11	2025	Q2	Corporate Banking	101.9372	4.919203e+07	71.000	-3767.300844
12	2025	Q2	Credit Card Services	99.0101	4.980885e+07	70.999	-3999.316319
13	2025	Q2	Financial Advisory	101.9666	4.990778e+07	73.000	-3919.582914
14	2025	Q2	Insurance	100.9409	5.020819e+07	71.000	-3720.728505
15	2025	Q2	Investment Banking	92.0268	4.974280e+07	62.999	-3890.210261
16	2025	Q2	Mortgage Lending	78.0187	4.982490e+07	52.000	-3527.646461
17	2025	Q2	Private Banking	90.9463	4.994254e+07	63.000	-4128.131603
18	2025	Q2	Retail	91.8694	4.996057e+07	64.000	-3547.024011
19	2025	Q2	Wealth Management	97.9966	4.977632e+07	69.000	-3597.750233
20	2025	Q3	Asset Management	87.8872	5.012981e+07	61.000	-3992.447626
21	2025	Q3	Corporate Banking	102.0721	4.970278e+07	73.000	-3924.206637
22	2025	Q3	Credit Card Services	99.2171	5.022994e+07	71.000	-3757.128131
23	2025	Q3	Financial Advisory	101.8237	4.972240e+07	73.000	-4092.111129
24	2025	Q3	Insurance	101.0239	4.980472e+07	70.999	-3453.958637
25	2025	Q3	Investment Banking	92.0232	4.918884e+07	65.000	-4039.358826
26	2025	Q3	Mortgage Lending	77.9528	4.993892e+07	52.000	-4038.651527
27	2025	Q3	Private Banking	90.9557	4.997236e+07	63.000	-3703.703319
28	2025	Q3	Retail	92.0308	5.026834e+07	64.999	-4348.077725
29	2025	Q3	Wealth Management	98.1530	5.038173e+07	69.000	-4013.622147
30	2025	Q4	Asset Management	88.0615	5.029675e+07	60.000	-3796.948589
31	2025	Q4	Corporate Banking	102.2616	4.956477e+07	73.000	-3816.070640
32	2025	Q4	Credit Card Services	98.6295	5.032075e+07	69.000	-3992.280462
33	2025	Q4	Financial Advisory	102.0310	4.987629e+07	72.999	-3759.774755
34	2025	Q4	Insurance	101.1266	4.932392e+07	71.000	-4091.838325
35	2025	Q4	Investment Banking	92.0569	5.000784e+07	64.000	-3876.229322
36	2025	Q4	Mortgage Lending	77.9845	4.987193e+07	52.999	-4288.005978
37	2025	Q4	Private Banking	90.8208	4.982658e+07	64.000	-3692.783527
38	2025	Q4	Retail	92.1605	4.987856e+07	64.000	-4365.141808
39	2025	Q4	Wealth Management	98.1442	4.986036e+07	69.998	-4224.706032
import pandas as pd
import numpy as np
from scipy import stats
from datetime import datetime, timedelta

# Function to generate random dates
def random_dates(start, end, n=10):
    return [start + timedelta(days=np.random.randint(0, (end - start).days)) for _ in range(n)]

# Parameters
num_records = 10000
start_date = datetime.now() - timedelta(days=4*365)
end_date = datetime.now()

# Expanded categories
business_lines = [
    "Retail", "Corporate Banking", "Investment Banking", "Insurance",
    "Wealth Management", "Asset Management", "Private Banking",
    "Credit Card Services", "Mortgage Lending", "Financial Advisory"
]

event_types = [
    "Fraud", "System Failure", "Theft", "Compliance", "Natural Disaster",
    "Cyber Attack", "Market Risk", "Operational Error", "Vendor Risk", "Regulatory Violation"
]

# Generate data
data = {
    "Date": random_dates(start_date, end_date, num_records),
    "Unique Event ID": [f"EID{str(i).zfill(5)}" for i in range(num_records)],
    "Event Type": np.random.choice(event_types, num_records),
    "Business Line": np.random.choice(business_lines, num_records),
    "Event Description": np.random.choice(
        [
            "Unauthorized transaction", "Server downtime", "Lost assets", 
            "Regulatory fines", "Data breach", "Network failure", 
            "Inadequate compliance", "Financial misstatement", 
            "Supplier issues", "Internal fraud"
        ],
        num_records
    ),
    "Net Loss Amount": np.random.choice(
        [np.random.uniform(-10000, 0) for _ in range(num_records // 2)] + 
        [np.random.uniform(0, 10000) for _ in range(num_records // 2)],
        num_records
    )
}

# Create DataFrame
df = pd.DataFrame(data)

# Step 1: Add 'Year' and 'Quarter' columns for analysis
df['Year'] = df['Date'].dt.year
df['Quarter'] = df['Date'].dt.quarter

# Step 2: Filter negative losses and fit the Weibull distribution
negative_losses = df[df['Net Loss Amount'] < 0]

# Fit a Weibull distribution to the negative losses
shape, loc, scale = stats.weibull_min.fit(-negative_losses['Net Loss Amount'])

# Step 3: Simulate future losses for 2025 using Weibull distribution
n_simulations = 10000  # Simulate 10,000 possible losses for each business line

simulated_losses = {}
for business_line in df['Business Line'].unique():
    # Simulate future losses using the Weibull distribution
    simulated_losses[business_line] = stats.weibull_min.rvs(shape, loc, scale, size=(n_simulations))

# Step 4: Simulate event counts for 2025
# Calculate historical event counts per business line per quarter in 2024
historical_event_counts = df[df['Year'] == 2024].groupby(['Business Line', 'Quarter']).size()

simulated_event_counts = {}
for business_line in df['Business Line'].unique():
    # Simulate event counts for the future (using historical distribution)
    event_counts_per_quarter = historical_event_counts.loc[business_line].values
    simulated_event_counts[business_line] = {
        quarter: np.random.choice(event_counts_per_quarter, size=n_simulations)
        for quarter in range(1, 5)
    }

# Step 5: Calculate VaR (99.9%) for Net Losses and Event Counts
confidence = 0.999  # 99.9% confidence level for VaR
var_results_2025 = []

# Loop over each business line to calculate VaR and event counts
for business_line in df['Business Line'].unique():
    for quarter in range(1, 5):
        # Simulate future event counts for this quarter
        event_count_simulations = simulated_event_counts[business_line][quarter]
        
        # Calculate VaR (99.9%) for event counts (using the 99.9th percentile of the simulation)
        var_event_counts_99_9 = np.percentile(event_count_simulations, (1 - confidence) * 100)
        
        # Calculate VaR (99.9%) for losses
        var_losses_99_9 = np.percentile(simulated_losses[business_line], (1 - confidence) * 100)
        
        # Event count for the quarter
        event_count = df[(df['Business Line'] == business_line) & (df['Quarter'] == quarter) & (df['Year'] == 2024)].shape[0]
        
        # Total predicted loss for the quarter
        total_quarter_loss = simulated_losses[business_line].sum()
        
        # Append results for this business line and quarter
        var_results_2025.append({
            'Year': 2025,
            'Quarter': quarter,
            'Business Line': business_line,
            'Predicted Event Count': event_count,
            'Predicted Event Count VaR (99.9%)': var_event_counts_99_9,
            'Total Predicted Loss Amount': total_quarter_loss,
            'VaR (99.9%) for Losses': var_losses_99_9
        })

# Step 6: Create DataFrame from the results
var_df_2025 = pd.DataFrame(var_results_2025)

# Step 7: Display the prediction results for 2025
print(var_df_2025)
    Year  Quarter         Business Line  Predicted Event Count  \
0   2025        1     Wealth Management                     70   
1   2025        2     Wealth Management                     61   
2   2025        3     Wealth Management                     61   
3   2025        4     Wealth Management                     41   
4   2025        1                Retail                     55   
5   2025        2                Retail                     61   
6   2025        3                Retail                     68   
7   2025        4                Retail                     34   
8   2025        1      Asset Management                     54   
9   2025        2      Asset Management                     65   
10  2025        3      Asset Management                     63   
11  2025        4      Asset Management                     39   
12  2025        1  Credit Card Services                     66   
13  2025        2  Credit Card Services                     68   
14  2025        3  Credit Card Services                     67   
15  2025        4  Credit Card Services                     34   
16  2025        1             Insurance                     68   
17  2025        2             Insurance                     56   
18  2025        3             Insurance                     68   
19  2025        4             Insurance                     27   
20  2025        1      Mortgage Lending                     58   
21  2025        2      Mortgage Lending                     52   
22  2025        3      Mortgage Lending                     51   
23  2025        4      Mortgage Lending                     40   
24  2025        1     Corporate Banking                     74   
25  2025        2     Corporate Banking                     60   
26  2025        3     Corporate Banking                     71   
27  2025        4     Corporate Banking                     42   
28  2025        1       Private Banking                     70   
29  2025        2       Private Banking                     62   
30  2025        3       Private Banking                     46   
31  2025        4       Private Banking                     32   
32  2025        1    Financial Advisory                     63   
33  2025        2    Financial Advisory                     63   
34  2025        3    Financial Advisory                     74   
35  2025        4    Financial Advisory                     27   
36  2025        1    Investment Banking                     58   
37  2025        2    Investment Banking                     52   
38  2025        3    Investment Banking                     65   
39  2025        4    Investment Banking                     38   

    Predicted Event Count VaR (99.9%)  Total Predicted Loss Amount  \
0                                41.0                 4.954531e+07   
1                                41.0                 4.954531e+07   
2                                41.0                 4.954531e+07   
3                                41.0                 4.954531e+07   
4                                34.0                 5.028150e+07   
5                                34.0                 5.028150e+07   
6                                34.0                 5.028150e+07   
7                                34.0                 5.028150e+07   
8                                39.0                 4.994997e+07   
9                                39.0                 4.994997e+07   
10                               39.0                 4.994997e+07   
11                               39.0                 4.994997e+07   
12                               34.0                 5.018092e+07   
13                               34.0                 5.018092e+07   
14                               34.0                 5.018092e+07   
15                               34.0                 5.018092e+07   
16                               27.0                 5.039309e+07   
17                               27.0                 5.039309e+07   
18                               27.0                 5.039309e+07   
19                               27.0                 5.039309e+07   
20                               40.0                 5.061699e+07   
21                               40.0                 5.061699e+07   
22                               40.0                 5.061699e+07   
23                               40.0                 5.061699e+07   
24                               42.0                 4.987985e+07   
25                               42.0                 4.987985e+07   
26                               42.0                 4.987985e+07   
27                               42.0                 4.987985e+07   
28                               32.0                 4.982607e+07   
29                               32.0                 4.982607e+07   
30                               32.0                 4.982607e+07   
31                               32.0                 4.982607e+07   
32                               27.0                 4.995682e+07   
33                               27.0                 4.995682e+07   
34                               27.0                 4.995682e+07   
35                               27.0                 4.995682e+07   
36                               38.0                 4.960142e+07   
37                               38.0                 4.960142e+07   
38                               38.0                 4.960142e+07   
39                               38.0                 4.960142e+07   

    VaR (99.9%) for Losses  
0              -681.484747  
1              -681.484747  
2              -681.484747  
3              -681.484747  
4              -706.993057  
5              -706.993057  
6              -706.993057  
7              -706.993057  
8              -678.583986  
9              -678.583986  
10             -678.583986  
11             -678.583986  
12             -740.927173  
13             -740.927173  
14             -740.927173  
15             -740.927173  
16             -596.353409  
17             -596.353409  
18             -596.353409  
19             -596.353409  
20             -765.616276  
21             -765.616276  
22             -765.616276  
23             -765.616276  
24             -760.456542  
25             -760.456542  
26             -760.456542  
27             -760.456542  
28             -716.062869  
29             -716.062869  
30             -716.062869  
31             -716.062869  
32             -689.813142  
33             -689.813142  
34             -689.813142  
35             -689.813142  
36             -746.325582  
37             -746.325582  
38             -746.325582  
39             -746.325582  
var_df_2025
Year	Quarter	Business Line	Predicted Event Count	Predicted Event Count VaR (99.9%)	Total Predicted Loss Amount	VaR (99.9%) for Losses
0	2025	1	Wealth Management	70	41.0	4.954531e+07	-681.484747
1	2025	2	Wealth Management	61	41.0	4.954531e+07	-681.484747
2	2025	3	Wealth Management	61	41.0	4.954531e+07	-681.484747
3	2025	4	Wealth Management	41	41.0	4.954531e+07	-681.484747
4	2025	1	Retail	55	34.0	5.028150e+07	-706.993057
5	2025	2	Retail	61	34.0	5.028150e+07	-706.993057
6	2025	3	Retail	68	34.0	5.028150e+07	-706.993057
7	2025	4	Retail	34	34.0	5.028150e+07	-706.993057
8	2025	1	Asset Management	54	39.0	4.994997e+07	-678.583986
9	2025	2	Asset Management	65	39.0	4.994997e+07	-678.583986
10	2025	3	Asset Management	63	39.0	4.994997e+07	-678.583986
11	2025	4	Asset Management	39	39.0	4.994997e+07	-678.583986
12	2025	1	Credit Card Services	66	34.0	5.018092e+07	-740.927173
13	2025	2	Credit Card Services	68	34.0	5.018092e+07	-740.927173
14	2025	3	Credit Card Services	67	34.0	5.018092e+07	-740.927173
15	2025	4	Credit Card Services	34	34.0	5.018092e+07	-740.927173
16	2025	1	Insurance	68	27.0	5.039309e+07	-596.353409
17	2025	2	Insurance	56	27.0	5.039309e+07	-596.353409
18	2025	3	Insurance	68	27.0	5.039309e+07	-596.353409
19	2025	4	Insurance	27	27.0	5.039309e+07	-596.353409
20	2025	1	Mortgage Lending	58	40.0	5.061699e+07	-765.616276
21	2025	2	Mortgage Lending	52	40.0	5.061699e+07	-765.616276
22	2025	3	Mortgage Lending	51	40.0	5.061699e+07	-765.616276
23	2025	4	Mortgage Lending	40	40.0	5.061699e+07	-765.616276
24	2025	1	Corporate Banking	74	42.0	4.987985e+07	-760.456542
25	2025	2	Corporate Banking	60	42.0	4.987985e+07	-760.456542
26	2025	3	Corporate Banking	71	42.0	4.987985e+07	-760.456542
27	2025	4	Corporate Banking	42	42.0	4.987985e+07	-760.456542
28	2025	1	Private Banking	70	32.0	4.982607e+07	-716.062869
29	2025	2	Private Banking	62	32.0	4.982607e+07	-716.062869
30	2025	3	Private Banking	46	32.0	4.982607e+07	-716.062869
31	2025	4	Private Banking	32	32.0	4.982607e+07	-716.062869
32	2025	1	Financial Advisory	63	27.0	4.995682e+07	-689.813142
33	2025	2	Financial Advisory	63	27.0	4.995682e+07	-689.813142
34	2025	3	Financial Advisory	74	27.0	4.995682e+07	-689.813142
35	2025	4	Financial Advisory	27	27.0	4.995682e+07	-689.813142
36	2025	1	Investment Banking	58	38.0	4.960142e+07	-746.325582
37	2025	2	Investment Banking	52	38.0	4.960142e+07	-746.325582
38	2025	3	Investment Banking	65	38.0	4.960142e+07	-746.325582
39	2025	4	Investment Banking	38	38.0	4.960142e+07	-746.325582
import pandas as pd
import numpy as np
from scipy import stats

# Assuming 'df' is the DataFrame already created as provided in the example.

# Step 1: Calculate the average event count per business line and event type from 2020 to 2024
event_count_avg_2020_2024 = df[df['Year'] < 2025].groupby(['Business Line', 'Event Type']).agg(
    Event_Count_Avg=('Unique Event ID', 'count')  # Count the number of Unique Event IDs for each Business Line and Event Type
).reset_index()

# Step 2: Fit a distribution (e.g., Weibull) to the historical losses (negative net loss amounts only)
negative_losses = df[df['Net Loss Amount'] < 0]
shape, loc, scale = stats.weibull_min.fit(negative_losses['Net Loss Amount'] * -1)

# Step 3: Simulate future losses (for 2025) for each business line using the fitted distribution
n_simulations = 10000  # Simulate 10,000 possible losses for each business line
simulated_losses = {}

for business_line in event_count_avg_2020_2024['Business Line'].unique():
    # Simulate future losses using the fitted Weibull distribution
    simulated_losses[business_line] = stats.weibull_min.rvs(shape, loc=loc, scale=scale, size=(n_simulations))

# Step 4: Calculate VaR (95%) for both Event Counts and Net Loss Amounts for 2025
confidence = 0.95  # 95% confidence level for VaR
var_results_2025 = {}

for business_line, losses in simulated_losses.items():
    # Calculate VaR for Net Loss Amounts at 95% confidence level
    var_net_loss_95 = np.percentile(losses, (1 - confidence) * 100)
    
    # Simulate event counts for 2025 based on the average event count per business line
    avg_event_count = event_count_avg_2020_2024[event_count_avg_2020_2024['Business Line'] == business_line]['Event_Count_Avg'].iloc[0]
    simulated_event_counts = np.random.poisson(lam=avg_event_count, size=n_simulations)
    
    # Calculate VaR for Event Counts at 95% confidence level
    var_event_count_95 = np.percentile(simulated_event_counts, (1 - confidence) * 100)
    
    # Sum of simulated losses for 2025
    total_loss = losses.sum()

    var_results_2025[business_line] = {
        'Year': 2025,
        'Business Line': business_line,
        'Predicted Event Count': avg_event_count,
        'Predicted Net Loss Amount': total_loss,
        'VaR (95%) for Event Counts': var_event_count_95,
        'VaR (95%) for Net Loss Amounts': var_net_loss_95
    }

# Step 5: Convert the results into a DataFrame
var_df_2025 = pd.DataFrame(var_results_2025).T

# Step 6: Display the prediction results for 2025
print(var_df_2025)
                      Year         Business Line Predicted Event Count  \
Asset Management      2025      Asset Management                    94   
Corporate Banking     2025     Corporate Banking                    99   
Credit Card Services  2025  Credit Card Services                    91   
Financial Advisory    2025    Financial Advisory                    84   
Insurance             2025             Insurance                    92   
Investment Banking    2025    Investment Banking                   112   
Mortgage Lending      2025      Mortgage Lending                   109   
Private Banking       2025       Private Banking                    95   
Retail                2025                Retail                    84   
Wealth Management     2025     Wealth Management                    82   

                     Predicted Net Loss Amount VaR (95%) for Event Counts  \
Asset Management               49958553.867578                       78.0   
Corporate Banking              50155675.630441                       83.0   
Credit Card Services           49787168.170491                       75.0   
Financial Advisory             50140212.977713                       69.0   
Insurance                      50041366.786127                       76.0   
Investment Banking             50025407.905917                       95.0   
Mortgage Lending                50059101.00599                       92.0   
Private Banking                50137767.865777                       79.0   
Retail                          50404611.47933                       69.0   
Wealth Management              50113362.632525                       67.0   

                     VaR (95%) for Net Loss Amounts  
Asset Management                         776.146159  
Corporate Banking                        752.568716  
Credit Card Services                     700.606622  
Financial Advisory                       723.699992  
Insurance                                751.571432  
Investment Banking                       740.531463  
Mortgage Lending                         787.569141  
Private Banking                           715.87988  
Retail                                   744.409552  
Wealth Management                        796.165224  
var_df_2025
Year	Business Line	Predicted Event Count	Predicted Net Loss Amount	VaR (95%) for Event Counts	VaR (95%) for Net Loss Amounts
Asset Management	2025	Asset Management	94	49958553.867578	78.0	776.146159
Corporate Banking	2025	Corporate Banking	99	50155675.630441	83.0	752.568716
Credit Card Services	2025	Credit Card Services	91	49787168.170491	75.0	700.606622
Financial Advisory	2025	Financial Advisory	84	50140212.977713	69.0	723.699992
Insurance	2025	Insurance	92	50041366.786127	76.0	751.571432
Investment Banking	2025	Investment Banking	112	50025407.905917	95.0	740.531463
Mortgage Lending	2025	Mortgage Lending	109	50059101.00599	92.0	787.569141
Private Banking	2025	Private Banking	95	50137767.865777	79.0	715.87988
Retail	2025	Retail	84	50404611.47933	69.0	744.409552
Wealth Management	2025	Wealth Management	82	50113362.632525	67.0	796.165224
import pandas as pd
import numpy as np
from scipy import stats

# Assuming the dataframe 'df' is already created and contains the relevant data

# Filter data for Q4 2024
df['Date'] = pd.to_datetime(df['Date'])  # Ensure 'Date' is in datetime format
q4_2024_df = df[(df['Date'].dt.year == 2024) & (df['Date'].dt.quarter == 4)]

# Step 1: Calculate the average event count for Q4 2024 for each business line
event_count_q4_2024 = q4_2024_df.groupby('Business Line')['Unique Event ID'].count().reset_index()
event_count_q4_2024 = event_count_q4_2024.rename(columns={'Unique Event ID': 'Event Count'})

# Step 2: Fit Poisson distribution for event counts (mean event count per business line)
simulated_event_counts = {}
for business_line in event_count_q4_2024['Business Line']:
    avg_event_count = event_count_q4_2024[event_count_q4_2024['Business Line'] == business_line]['Event Count'].iloc[0]
    simulated_event_counts[business_line] = np.random.poisson(lam=avg_event_count, size=10000)

# Step 3: Fit Weibull distribution for net losses (only for negative net losses)
negative_losses_q4_2024 = q4_2024_df[q4_2024_df['Net Loss Amount'] < 0]
shape, loc, scale = stats.weibull_min.fit(-negative_losses_q4_2024['Net Loss Amount'])  # Negative for fitting

# Simulate net losses for Q4 2024 using Weibull distribution
simulated_net_losses = {}
for business_line in event_count_q4_2024['Business Line']:
    simulated_net_losses[business_line] = stats.weibull_min.rvs(shape, loc=loc, scale=scale, size=10000)

# Step 4: Calculate VaR (99.9%) for both event counts and net losses
confidence = 0.999  # 99.9% confidence level
var_event_counts = {}
var_net_losses = {}

# Calculate VaR for Event Counts and Net Losses
for business_line in event_count_q4_2024['Business Line']:
    # Event Count VaR
    var_event_counts[business_line] = np.percentile(simulated_event_counts[business_line], (1 - confidence) * 100)
    
    # Net Loss VaR (absolute value, as losses are negative)
    var_net_losses[business_line] = np.percentile(simulated_net_losses[business_line], (1 - confidence) * 100)

# Combine all results into a final DataFrame
final_results_q4_2024 = pd.DataFrame({
    'Business Line': event_count_q4_2024['Business Line'],
    'Predicted Event Count': event_count_q4_2024['Event Count'],
    'VaR Event Count (99.9%)': [var_event_counts[bl] for bl in event_count_q4_2024['Business Line']],
    'VaR Net Loss (99.9%)': [var_net_losses[bl] for bl in event_count_q4_2024['Business Line']]
})

print(final_results_q4_2024)
          Business Line  Predicted Event Count  VaR Event Count (99.9%)  \
0      Asset Management                     39                   21.000   
1     Corporate Banking                     42                   24.000   
2  Credit Card Services                     34                   18.000   
3    Financial Advisory                     27                   13.000   
4             Insurance                     27                   13.000   
5    Investment Banking                     38                   20.000   
6      Mortgage Lending                     40                   22.000   
7       Private Banking                     32                   16.000   
8                Retail                     34                   17.999   
9     Wealth Management                     41                   23.000   

   VaR Net Loss (99.9%)  
0           -528.201877  
1           -584.306393  
2           -567.459545  
3           -460.127375  
4           -492.227097  
5           -454.562506  
6           -534.403128  
7           -581.293707  
8           -647.176373  
9           -647.663795  
final_results_q4_2024
Business Line	Predicted Event Count	VaR Event Count (99.9%)	VaR Net Loss (99.9%)
0	Asset Management	39	21.000	-528.201877
1	Corporate Banking	42	24.000	-584.306393
2	Credit Card Services	34	18.000	-567.459545
3	Financial Advisory	27	13.000	-460.127375
4	Insurance	27	13.000	-492.227097
5	Investment Banking	38	20.000	-454.562506
6	Mortgage Lending	40	22.000	-534.403128
7	Private Banking	32	16.000	-581.293707
8	Retail	34	17.999	-647.176373
9	Wealth Management	41	23.000	-647.663795
# Assuming the DataFrame `df` already contains the actual values

# Step 1: Extract actual data for Q4 2024
actual_q4_2024 = df[(df['Date'].dt.year == 2024) & (df['Date'].dt.quarter == 4)]

# Step 2: Calculate the actual event count for each business line in Q4 2024
actual_event_count_q4_2024 = actual_q4_2024.groupby('Business Line')['Unique Event ID'].count().reset_index()
actual_event_count_q4_2024 = actual_event_count_q4_2024.rename(columns={'Unique Event ID': 'Actual Event Count'})

# Step 3: Calculate the actual net loss for each business line in Q4 2024
actual_net_loss_q4_2024 = actual_q4_2024.groupby('Business Line')['Net Loss Amount'].sum().reset_index()

# Step 4: Merge actual data with the predicted data (for VaR and counts)
final_results_q4_2024['Actual Event Count'] = [actual_event_count_q4_2024[actual_event_count_q4_2024['Business Line'] == bl]['Actual Event Count'].iloc[0]
                                               for bl in final_results_q4_2024['Business Line']]
final_results_q4_2024['Actual Net Loss'] = [actual_net_loss_q4_2024[actual_net_loss_q4_2024['Business Line'] == bl]['Net Loss Amount'].iloc[0]
                                            for bl in final_results_q4_2024['Business Line']]

# Step 5: Calculate the differences
final_results_q4_2024['Event Count Difference'] = final_results_q4_2024['Actual Event Count'] - final_results_q4_2024['Predicted Event Count']
final_results_q4_2024['Net Loss Difference'] = final_results_q4_2024['Actual Net Loss'] - final_results_q4_2024['Predicted Net Loss']

# Step 6: Display or visualize the results
print(final_results_q4_2024)

# Optionally, you can visualize the differences
import matplotlib.pyplot as plt

# Plot Event Count Differences
plt.figure(figsize=(10, 6))
plt.bar(final_results_q4_2024['Business Line'], final_results_q4_2024['Event Count Difference'])
plt.xlabel('Business Line')
plt.ylabel('Event Count Difference (Actual - Predicted)')
plt.title('Event Count Differences for Q4 2024')
plt.xticks(rotation=45, ha='right')
plt.show()

# Plot Net Loss Differences
plt.figure(figsize=(10, 6))
plt.bar(final_results_q4_2024['Business Line'], final_results_q4_2024['Net Loss Difference'])
plt.xlabel('Business Line')
plt.ylabel('Net Loss Difference (Actual - Predicted)')
plt.title('Net Loss Differences for Q4 2024')
plt.xticks(rotation=45, ha='right')
plt.show()
 
 
#t dustribution import pandas as pd
import numpy as np
from scipy import stats

# Step 1: Fit a Student's t-distribution to the negative losses
def fit_t_distribution(data):
    # Remove zero or negative values as the t-distribution is for positive data
    data = data[data < 0] * -1  # Convert negative losses to positive for fitting
    
    # Fit t-distribution: returns (df, loc, scale) -> degrees of freedom, location, scale
    df, loc, scale = stats.t.fit(data)
    return df, loc, scale

# Step 2: Apply the t-distribution to the historical data
negative_losses = df[df['Net Loss Amount'] < 0]

# Fit the t-distribution to the negative losses
df, loc, scale = fit_t_distribution(negative_losses['Net Loss Amount'])

# Step 3: Simulate future losses for 2025
n_simulations = 10000  # Number of simulations for future losses
simulated_losses = {}

quarters = ['Q1', 'Q2', 'Q3', 'Q4']
for quarter in quarters:
    simulated_losses[quarter] = {}
    
    for business_line in event_count_avg_2020_2024['Business Line'].unique():
        # Simulate losses using the fitted t-distribution
        simulated_losses[quarter][business_line] = stats.t.rvs(df, loc=loc, scale=scale, size=n_simulations)

# Step 4: Calculate VaR at 99.9% confidence level for each quarter
confidence = 0.999  # 99.9% confidence level for VaR
var_results = {}

for quarter, losses_by_business_line in simulated_losses.items():
    for business_line, losses in losses_by_business_line.items():
        var_99_9 = np.percentile(losses, (1 - confidence) * 100)  # Calculate VaR at 99.9% confidence level
        
        # Get the average event count for the business line for the current quarter
        event_count = event_count_avg_2020_2024[
            (event_count_avg_2020_2024['Business Line'] == business_line)
        ]['Event_Count_Avg'].iloc[0]

        total_loss = losses.sum()  # Total simulated loss for 2025

        # Store results
        var_results[(quarter, business_line)] = {
            'Quarter': quarter,
            'Business Line': business_line,
            'Predicted Event Count': event_count,
            'Total Predicted Loss Amount': total_loss,
            'VaR (99.9%)': var_99_9
        }

# Step 5: Convert the results into a DataFrame for easy viewing
var_df_2025 = pd.DataFrame(var_results).T

# Step 6: Display the prediction results for 2025 by quarter
print(var_df_2025)
                        Quarter         Business Line Predicted Event Count  \
Q1 Asset Management          Q1      Asset Management                    88   
   Corporate Banking         Q1     Corporate Banking                   102   
   Credit Card Services      Q1  Credit Card Services                    99   
   Financial Advisory        Q1    Financial Advisory                   102   
   Insurance                 Q1             Insurance                   101   
   Investment Banking        Q1    Investment Banking                    92   
   Mortgage Lending          Q1      Mortgage Lending                    78   
   Private Banking           Q1       Private Banking                    91   
   Retail                    Q1                Retail                    92   
   Wealth Management         Q1     Wealth Management                    98   
Q2 Asset Management          Q2      Asset Management                    88   
   Corporate Banking         Q2     Corporate Banking                   102   
   Credit Card Services      Q2  Credit Card Services                    99   
   Financial Advisory        Q2    Financial Advisory                   102   
   Insurance                 Q2             Insurance                   101   
   Investment Banking        Q2    Investment Banking                    92   
   Mortgage Lending          Q2      Mortgage Lending                    78   
   Private Banking           Q2       Private Banking                    91   
   Retail                    Q2                Retail                    92   
   Wealth Management         Q2     Wealth Management                    98   
Q3 Asset Management          Q3      Asset Management                    88   
   Corporate Banking         Q3     Corporate Banking                   102   
   Credit Card Services      Q3  Credit Card Services                    99   
   Financial Advisory        Q3    Financial Advisory                   102   
   Insurance                 Q3             Insurance                   101   
   Investment Banking        Q3    Investment Banking                    92   
   Mortgage Lending          Q3      Mortgage Lending                    78   
   Private Banking           Q3       Private Banking                    91   
   Retail                    Q3                Retail                    92   
   Wealth Management         Q3     Wealth Management                    98   
Q4 Asset Management          Q4      Asset Management                    88   
   Corporate Banking         Q4     Corporate Banking                   102   
   Credit Card Services      Q4  Credit Card Services                    99   
   Financial Advisory        Q4    Financial Advisory                   102   
   Insurance                 Q4             Insurance                   101   
   Investment Banking        Q4    Investment Banking                    92   
   Mortgage Lending          Q4      Mortgage Lending                    78   
   Private Banking           Q4       Private Banking                    91   
   Retail                    Q4                Retail                    92   
   Wealth Management         Q4     Wealth Management                    98   

                        Total Predicted Loss Amount  VaR (99.9%)  
Q1 Asset Management                 49968332.002493 -4413.165763  
   Corporate Banking                  50112543.6084 -3639.175236  
   Credit Card Services             49824979.982347 -3657.507583  
   Financial Advisory               50543287.741045 -3779.224471  
   Insurance                        50044197.800297 -3971.603513  
   Investment Banking               50153953.664639 -3918.272821  
   Mortgage Lending                 50463610.929035 -3967.994027  
   Private Banking                  49800489.084082 -3925.160885  
   Retail                           49730573.861089 -4135.214896  
   Wealth Management                50329751.658355 -3894.705676  
Q2 Asset Management                 49703914.061929 -3721.875731  
   Corporate Banking                50163214.644501 -3968.872653  
   Credit Card Services             50532687.556606  -3799.54317  
   Financial Advisory               49691569.014958 -3590.300119  
   Insurance                        49930067.311142 -4171.734898  
   Investment Banking               50027881.702752  -4171.27782  
   Mortgage Lending                 50170153.545584 -3878.452037  
   Private Banking                  50076543.563895 -4044.354659  
   Retail                           49810715.584318 -4092.695525  
   Wealth Management                49524414.511709 -4763.936268  
Q3 Asset Management                 50337540.979995 -3927.064712  
   Corporate Banking                49974778.976449 -4138.352915  
   Credit Card Services              50159004.14271 -3924.238712  
   Financial Advisory               50100660.242848 -3730.815804  
   Insurance                        49892979.167421 -4002.540074  
   Investment Banking               49604956.904194  -4003.86478  
   Mortgage Lending                 49588509.452468 -3623.797296  
   Private Banking                  49943537.183954 -4015.133804  
   Retail                           50402156.952659 -3485.617466  
   Wealth Management                50301606.189474 -3741.849069  
Q4 Asset Management                 49984048.272637 -3853.646315  
   Corporate Banking                50068700.431815 -4034.094304  
   Credit Card Services             49737973.320131 -4444.798987  
   Financial Advisory               49832554.870139 -4571.126056  
   Insurance                        50072313.883767 -3751.976337  
   Investment Banking               49988145.534809 -3917.359849  
   Mortgage Lending                 49847156.720259 -3776.739398  
   Private Banking                  50137111.292883  -3819.11874  
   Retail                           49971837.829861 -4030.118845  
   Wealth Management                50022677.202408 -4022.523808  
var_df_2025
Quarter	Business Line	Predicted Event Count	Total Predicted Loss Amount	VaR (99.9%)
Q1	Asset Management	Q1	Asset Management	88	49968332.002493	-4413.165763
Corporate Banking	Q1	Corporate Banking	102	50112543.6084	-3639.175236
Credit Card Services	Q1	Credit Card Services	99	49824979.982347	-3657.507583
Financial Advisory	Q1	Financial Advisory	102	50543287.741045	-3779.224471
Insurance	Q1	Insurance	101	50044197.800297	-3971.603513
Investment Banking	Q1	Investment Banking	92	50153953.664639	-3918.272821
Mortgage Lending	Q1	Mortgage Lending	78	50463610.929035	-3967.994027
Private Banking	Q1	Private Banking	91	49800489.084082	-3925.160885
Retail	Q1	Retail	92	49730573.861089	-4135.214896
Wealth Management	Q1	Wealth Management	98	50329751.658355	-3894.705676
Q2	Asset Management	Q2	Asset Management	88	49703914.061929	-3721.875731
Corporate Banking	Q2	Corporate Banking	102	50163214.644501	-3968.872653
Credit Card Services	Q2	Credit Card Services	99	50532687.556606	-3799.54317
Financial Advisory	Q2	Financial Advisory	102	49691569.014958	-3590.300119
Insurance	Q2	Insurance	101	49930067.311142	-4171.734898
Investment Banking	Q2	Investment Banking	92	50027881.702752	-4171.27782
Mortgage Lending	Q2	Mortgage Lending	78	50170153.545584	-3878.452037
Private Banking	Q2	Private Banking	91	50076543.563895	-4044.354659
Retail	Q2	Retail	92	49810715.584318	-4092.695525
Wealth Management	Q2	Wealth Management	98	49524414.511709	-4763.936268
Q3	Asset Management	Q3	Asset Management	88	50337540.979995	-3927.064712
Corporate Banking	Q3	Corporate Banking	102	49974778.976449	-4138.352915
Credit Card Services	Q3	Credit Card Services	99	50159004.14271	-3924.238712
Financial Advisory	Q3	Financial Advisory	102	50100660.242848	-3730.815804
Insurance	Q3	Insurance	101	49892979.167421	-4002.540074
Investment Banking	Q3	Investment Banking	92	49604956.904194	-4003.86478
Mortgage Lending	Q3	Mortgage Lending	78	49588509.452468	-3623.797296
Private Banking	Q3	Private Banking	91	49943537.183954	-4015.133804
Retail	Q3	Retail	92	50402156.952659	-3485.617466
Wealth Management	Q3	Wealth Management	98	50301606.189474	-3741.849069
Q4	Asset Management	Q4	Asset Management	88	49984048.272637	-3853.646315
Corporate Banking	Q4	Corporate Banking	102	50068700.431815	-4034.094304
Credit Card Services	Q4	Credit Card Services	99	49737973.320131	-4444.798987
Financial Advisory	Q4	Financial Advisory	102	49832554.870139	-4571.126056
Insurance	Q4	Insurance	101	50072313.883767	-3751.976337
Investment Banking	Q4	Investment Banking	92	49988145.534809	-3917.359849
Mortgage Lending	Q4	Mortgage Lending	78	49847156.720259	-3776.739398
Private Banking	Q4	Private Banking	91	50137111.292883	-3819.11874
Retail	Q4	Retail	92	49971837.829861	-4030.118845
Wealth Management	Q4	Wealth Management	98	50022677.202408	-4022.523808
 
 
is there ant alternates lognorm more better mehos

ChatGPT said:
ChatGPT
Yes, there are several alternative methods to the log-normal distribution for modeling losses, especially in the context of risk management or financial losses. The log-normal distribution is popular because it can model positive skewness and heavy tails often seen in financial loss distributions, but other distributions or methods might be better suited depending on the nature of your data. Below are some alternatives you can consider:

1. Weibull Distribution
Use Case: The Weibull distribution is often used for modeling extreme values or rare events, such as insurance claims or extreme operational losses.
Strengths: It can model both light-tailed and heavy-tailed data, making it more flexible than log-normal in some cases.
Fitting: It can be fit using maximum likelihood estimation or method of moments.
python
Copy code
from scipy import stats
shape, loc, scale = stats.weibull_min.fit(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.weibull_min.rvs(shape, loc, scale, size=(n_simulations))
2. Pareto Distribution (Heavy-Tailed)
Use Case: Pareto distributions are well-suited for modeling extreme events that are rare but severe, such as extreme operational risk or large financial losses.
Strengths: It models distributions with heavy tails, which is a characteristic of operational or market risk.
Fitting: The Pareto distribution has a simple form and can be fitted using maximum likelihood estimation.
python
Copy code
shape, loc, scale = stats.pareto.fit(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.pareto.rvs(shape, loc, scale, size=(n_simulations))
3. Gamma Distribution
Use Case: Gamma distributions are often used for modeling time-to-failure or event-driven processes (e.g., claims, losses).
Strengths: Gamma distribution is flexible and can model right-skewed data, similar to log-normal but with more control over the shape of the distribution.
Fitting: It can also be fitted using maximum likelihood estimation.
python
Copy code
shape, loc, scale = stats.gamma.fit(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.gamma.rvs(shape, loc, scale, size=(n_simulations))
4. Exponential Distribution
Use Case: Exponential distributions are a special case of the Gamma distribution and are typically used to model the time between events in Poisson processes (e.g., time between operational losses).
Strengths: It's easy to fit and suitable for modeling events that occur at a constant average rate.
Limitations: It is less flexible compared to the log-normal or Gamma when the data exhibits more variability or heavy tails.
python
Copy code
scale = np.mean(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.expon.rvs(scale=scale, size=(n_simulations))
5. Generalized Pareto Distribution (GPD)
Use Case: The Generalized Pareto Distribution (GPD) is used in extreme value theory to model the tail of a distribution and is particularly suitable for modeling rare and extreme events (e.g., large losses).
Strengths: It is ideal for tail-fitting in extreme value analysis, especially for financial or operational risk where you are concerned about extreme loss events.
Fitting: It can be fitted using Maximum Likelihood Estimation (MLE) or Hill Estimator for tail-fitting.
python
Copy code
shape, loc, scale = stats.genpareto.fit(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.genpareto.rvs(shape, loc, scale, size=(n_simulations))
6. Empirical Distribution (Non-Parametric)
Use Case: If you prefer to avoid making assumptions about the distribution of your data, you can use an empirical distribution derived directly from your historical data.
Strengths: This method doesn't require any assumptions about the underlying distribution and can capture the exact characteristics of the observed data.
Fitting: Empirical distributions can be generated using bootstrapping or kernel density estimation (KDE).
python
Copy code
simulated_losses = np.random.choice(negative_losses['Net Loss Amount'] * -1, size=(n_simulations), replace=True)
7. Studentâs t-Distribution
Use Case: The Studentâs t-distribution is useful when you have heavy tails (more extreme values in the data), which is common in financial or risk modeling.
Strengths: It can model data with extreme values better than the normal distribution.
Fitting: It can be fitted using method of moments or maximum likelihood estimation.
python
Copy code
df, loc, scale = stats.t.fit(negative_losses['Net Loss Amount'] * -1)
simulated_losses = stats.t.rvs(df, loc, scale, size=(n_simulations))
8. Copulas (for Multivariate Loss Modeling)
Use Case: If you want to model dependencies between multiple loss variables (e.g., between event count and loss amount), you can use copulas to simulate correlated losses.
Strengths: Copulas allow for modeling dependencies between different random variables, giving a more complete picture of the joint distribution of multiple risks.
Fitting: Fitting copulas can be more complex, requiring estimation of the copula parameter using methods such as maximum likelihood or inference functions.
python
Copy code
import copulas
from copulas.univariate import GaussianKDE
from copulas.bivariate import Clayton

# Fit the univariate marginal distributions
marginal_loss = GaussianKDE()
marginal_loss.fit(negative_losses['Net Loss Amount'])

# Fit the copula model
copula = Clayton()
copula.fit(marginal_loss)

# Simulate losses with copulas
simulated_losses = copula.sample(n_simulations)
Choosing the Best Method
Heavy-Tailed Losses: If you're dealing with heavy-tailed losses (e.g., rare but severe events), distributions like the Pareto, Weibull, GPD, or Studentâs t-distribution might be more appropriate than the log-normal.
Skewed Data: If your data is skewed but not necessarily heavy-tailed, the log-normal or Gamma distribution might still be a good fit.
Empirical Data: If you have a large amount of historical data, and you want to avoid assuming any specific distribution, using empirical bootstrapping or kernel density estimation (KDE) might work well.
Multivariate Models: If you're modeling correlated risks (e.g., losses in different business lines), consider copulas.
Next Steps:
Visualize Data: Itâs always a good idea to visualize your data (e.g., using histograms or Q-Q plots) to understand its distribution before choosing a model.
Goodness-of-Fit Tests: After fitting a distribution, perform goodness-of-fit tests (e.g., Kolmogorov-Smirnov test, Anderson-Darling test) to compare how well the fitted model matches the data.
Let me know if you'd like further details or implementation examples!
  Cell In[4], line 34
    Strengths: It's easy to fit and suitable for modeling events that occur at a constant average rate.
                 ^
SyntaxError: unterminated string literal (detected at line 34)
 
